{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import gym\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "# choose a GPU card\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(object):\n",
    "\n",
    "    def __init__(self, state_size, action_size, learning_rate, name='PolicyNetwork'):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            with tf.name_scope(\"inputs\"):\n",
    "                self.inputs = tf.placeholder(tf.float32, [None,state_size], name = \"inputs_\")\n",
    "                # Jieda note: we are using sparse_softmax_cross_entropy_with_logits, so action is now a scaler (instead of a vector)\n",
    "                self.actions = tf.placeholder(tf.int32, [None,], name =\"actions\")\n",
    "                self.discounted_episode_rewards = tf.placeholder(tf.float32, [None,], name=\"discounted_episode_rewards_\")\n",
    "                # Jieda note: place holder for the ValueNetwork esitimated value\n",
    "                # Jieda note: following line is commented out, because feed the results from dis_sample_total_rewards - value_estimates\n",
    "                # directly to discounted_episode_rewards\n",
    "                # self.value_estimate = tf.placeholder(tf.float32, [None,], name=\"value_estimate_\")\n",
    "\n",
    "            with tf.name_scope(\"fc1\"):\n",
    "                self.fc1 = tf.layers.dense(inputs=self.inputs,\n",
    "                                          units = 256, activation = tf.nn.relu,\n",
    "                                          kernel_initializer = tf.contrib.layers.xavier_initializer(), name = \"fc1\")\n",
    "\n",
    "            with tf.name_scope(\"fc2\"):\n",
    "                self.fc2 = tf.layers.dense(inputs = self.fc1,\n",
    "                                           units = 256, activation = tf.nn.relu,\n",
    "                                           kernel_initializer = tf.contrib.layers.xavier_initializer(), name = 'fc2')\n",
    "\n",
    "            with tf.name_scope(\"logits\"):\n",
    "                self.logits = tf.layers.dense(inputs = self.fc2,\n",
    "                                              units = action_size,\n",
    "                                              kernel_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "                                              activation = None)\n",
    "            with tf.name_scope(\"softmax\"):\n",
    "                self.action_distribution = tf.nn.softmax(self.logits)\n",
    "\n",
    "            with tf.name_scope(\"loss\"):\n",
    "                self.cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = self.logits, labels =self.actions)\n",
    "                # Jieda noted: for baseline, we subtract the value_estimate_ from discounted_episode_rewards\n",
    "                self.weighted_negative_likelihoods = tf.multiply(self.cross_entropy, (self.discounted_episode_rewards))\n",
    "                self.loss = tf.reduce_mean(self.weighted_negative_likelihoods)\n",
    "\n",
    "            with tf.name_scope(\"train\"):\n",
    "                self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "                self.train_opt = self.optimizer.minimize(self.loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the value function network\n",
    "## input is the size of state, output is a single value\n",
    "class ValueNetwork(object):\n",
    "\n",
    "    def __init__(self, state_size, learning_rate, name='ValueNetwork'):\n",
    "        self.state_size = state_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            with tf.name_scope(\"inputs\"):\n",
    "                self.inputs = tf.placeholder(tf.float32, [None,state_size], name = \"inputs_\")\n",
    "                self.target = tf.placeholder(tf.float32, [None,], name = \"target\")\n",
    "\n",
    "            with tf.name_scope(\"value_fc1\"):\n",
    "                self.fc1 = tf.layers.dense(inputs=self.inputs,\n",
    "                                          units = 256, activation = tf.nn.relu,\n",
    "                                          kernel_initializer = tf.contrib.layers.xavier_initializer(), name = \"value_fc1\")\n",
    "\n",
    "            with tf.name_scope(\"value_fc2\"):\n",
    "                self.fc2 = tf.layers.dense(inputs = self.fc1,\n",
    "                                           units = 256, activation = tf.nn.relu,\n",
    "                                           kernel_initializer = tf.contrib.layers.xavier_initializer(), name = 'value_fc2')\n",
    "            with tf.name_scope(\"output\"):\n",
    "                self.output_layer = tf.layers.dense(\n",
    "                inputs=self.fc2,\n",
    "                units = 1,\n",
    "                activation = None,\n",
    "                kernel_initializer = tf.contrib.layers.xavier_initializer(), name = \"output\")\n",
    "            \n",
    "            \n",
    "            with tf.name_scope(\"loss\"):\n",
    "                self.value_estimate = tf.squeeze(self.output_layer)\n",
    "                self.loss = tf.squared_difference(self.value_estimate, self.target)\n",
    "\n",
    "            with tf.name_scope(\"train\"):\n",
    "                self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "                self.train_opt = self.optimizer.minimize(self.loss)\n",
    "    \n",
    "    \n",
    "    # method to update the Value neuron network parameters\n",
    "    def update(self, state, target, sess=None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        feed_dict = {self.inputs: state, self.target:target}\n",
    "        _, loss = sess.run([self.train_opt, self.loss], feed_dict)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function\n",
    "### calculates the discounted total rewards from current step onward\n",
    "\n",
    "def discount_rewards(r, gamma=0.95, normalization=False):\n",
    "    \"\"\"\n",
    "    computes the discounted rewards from time t onward for a given episode\n",
    "    length of r corresponds to the number of steps in an episode\n",
    "    discounted_r has the same length --> discounted rewards at each time step\n",
    "    \"\"\"\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    for i in reversed(range(0, len(r))):\n",
    "        running_add = running_add * gamma + r[i]\n",
    "        discounted_r[i] = running_add\n",
    "\n",
    "    if normalization:\n",
    "        mean = np.mean(discounted_r)\n",
    "        std = np.std(discounted_r)\n",
    "        discounted_r = (discounted_r - mean) / (std)\n",
    "\n",
    "    return discounted_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# environment parameters\n",
    "state_size = 4\n",
    "action_size = env.action_space.n\n",
    "possible_actions = np.identity(action_size,dtype=int).tolist()\n",
    "\n",
    "# training hyperparameters\n",
    "learning_rate = 0.002\n",
    "num_epochs = 200\n",
    "batch_size = 1000 # each 1 is a timestep (not an episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================\n",
    "# run policy\n",
    "#============================\n",
    "def make_batch(batch_size):\n",
    "\n",
    "    \"\"\"\n",
    "    We will run the policy and generate a bunch of episodes\n",
    "    We need to keep track of (st,at,rt,st+1) for each of the episode, those we will use for training\n",
    "    :param batch_size: number of episodes in a batch\n",
    "    :return: 3 list: states, actions, rewards of batch (each value is accumulated discounted total rewards)\n",
    "    \"\"\"\n",
    "    # initialize lists:\n",
    "\n",
    "    states, actions, rewards_of_episode, rewards_of_batch, discounted_rewards = [], [], [], [], []\n",
    "    # number of episode in batch\n",
    "    episode_num = 1\n",
    "\n",
    "    # Get a new state\n",
    "    state = env.reset()\n",
    "\n",
    "    while True:\n",
    "        # run state through policy and calculate action\n",
    "        action_probability_distribution = sess.run(PolicyNetwork.action_distribution, feed_dict={PolicyNetwork.inputs: state.reshape(1,state_size)})\n",
    "\n",
    "        # choose action\n",
    "        action = np.random.choice(range(action_probability_distribution.shape[1]), p=action_probability_distribution.ravel())\n",
    "\n",
    "        # perform action\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # the 3 lists here tracks the quantity for each episode\n",
    "        # the other 2 lists (rewards_of_batch and discounted_rewards, they are both list of list)\n",
    "        # they contain num_episode list and each list is the rewards of that episode of each time stamp\n",
    "        # rewards_of_batch is UNdiscounted, discounted_rewards is DISCOUNTED and counts from time t onwards\n",
    "        # in the calculation of loss function, we need the discounted_rewards\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards_of_episode.append(reward)\n",
    "\n",
    "        if done:\n",
    "            # if the entire episode is done\n",
    "\n",
    "            # if you have more than 1 episode in a batch, we track rewards of each episode in the batch\n",
    "            # this is undiscounted rewards, we WILL use this to do the plotting\n",
    "            rewards_of_batch.append(rewards_of_episode)\n",
    "\n",
    "            # disc_rwds_per_episode is a list with each element being the discounted reward from a time stamp t onward\n",
    "            disc_rwds_per_episode = discount_rewards(rewards_of_episode, gamma=0.99, normalization=True)\n",
    "            # discounted_rewards is a list of lenth (number of episode)\n",
    "            discounted_rewards.append(disc_rwds_per_episode)\n",
    "            #\n",
    "            if len(np.concatenate(rewards_of_batch)) > batch_size:\n",
    "                break\n",
    "            # reset the transition stores\n",
    "            rewards_of_episode = []\n",
    "            # add episode\n",
    "            episode_num += 1\n",
    "            # reset the state\n",
    "            state = env.reset()\n",
    "\n",
    "        else:\n",
    "            # if not done, the next_state become the current state\n",
    "            state = next_state\n",
    "\n",
    "    # Essentially, we will keep records of (state, action, rewards), need those for training!\n",
    "    return np.stack(np.array(states)), np.stack(np.array(actions)), np.concatenate(rewards_of_batch), np.concatenate(discounted_rewards),episode_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-2-7f6663fbb491>:22: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /nfs/home/jlg7773/.conda/envs/dl/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /nfs/home/jlg7773/.conda/envs/dl/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# reset the graph\n",
    "tf.reset_default_graph()\n",
    "# tf.reset_default_graph()\n",
    "#==============================\n",
    "#  Initialize network and session\n",
    "#==============================\n",
    "# Instantiate the PolicyNetwork\n",
    "PolicyNetwork = PolicyNetwork(state_size, action_size, learning_rate)\n",
    "# Instantiate the ValueNetwork\n",
    "ValueNetwork = ValueNetwork(state_size, learning_rate)\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Epoch:  1 / 500\n",
      "Number of training episodes: 30\n",
      "Total reward: 1031.0\n",
      "Mean Reward of that batch 34.36666666666667\n",
      "Average Reward of all training: 34.36666666666667\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  2 / 500\n",
      "Number of training episodes: 26\n",
      "Total reward: 1043.0\n",
      "Mean Reward of that batch 40.11538461538461\n",
      "Average Reward of all training: 37.241025641025644\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  3 / 500\n",
      "Number of training episodes: 26\n",
      "Total reward: 1041.0\n",
      "Mean Reward of that batch 40.03846153846154\n",
      "Average Reward of all training: 38.17350427350428\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  4 / 500\n",
      "Number of training episodes: 30\n",
      "Total reward: 1013.0\n",
      "Mean Reward of that batch 33.766666666666666\n",
      "Average Reward of all training: 37.07179487179488\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  5 / 500\n",
      "Number of training episodes: 25\n",
      "Total reward: 1040.0\n",
      "Mean Reward of that batch 41.6\n",
      "Average Reward of all training: 37.9774358974359\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  6 / 500\n",
      "Number of training episodes: 25\n",
      "Total reward: 1043.0\n",
      "Mean Reward of that batch 41.72\n",
      "Average Reward of all training: 38.60119658119658\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  7 / 500\n",
      "Number of training episodes: 22\n",
      "Total reward: 1057.0\n",
      "Mean Reward of that batch 48.04545454545455\n",
      "Average Reward of all training: 39.9503762903763\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  8 / 500\n",
      "Number of training episodes: 26\n",
      "Total reward: 1014.0\n",
      "Mean Reward of that batch 39.0\n",
      "Average Reward of all training: 39.83157925407926\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  9 / 500\n",
      "Number of training episodes: 25\n",
      "Total reward: 1014.0\n",
      "Mean Reward of that batch 40.56\n",
      "Average Reward of all training: 39.9125148925149\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  10 / 500\n",
      "Number of training episodes: 19\n",
      "Total reward: 1009.0\n",
      "Mean Reward of that batch 53.10526315789474\n",
      "Average Reward of all training: 41.231789719052884\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  11 / 500\n",
      "Number of training episodes: 25\n",
      "Total reward: 1037.0\n",
      "Mean Reward of that batch 41.48\n",
      "Average Reward of all training: 41.25435429004808\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  12 / 500\n",
      "Number of training episodes: 17\n",
      "Total reward: 1054.0\n",
      "Mean Reward of that batch 62.0\n",
      "Average Reward of all training: 42.98315809921073\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  13 / 500\n",
      "Number of training episodes: 23\n",
      "Total reward: 1029.0\n",
      "Mean Reward of that batch 44.73913043478261\n",
      "Average Reward of all training: 43.118232894254724\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  14 / 500\n",
      "Number of training episodes: 18\n",
      "Total reward: 1099.0\n",
      "Mean Reward of that batch 61.05555555555556\n",
      "Average Reward of all training: 44.39947022720479\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  15 / 500\n",
      "Number of training episodes: 24\n",
      "Total reward: 1039.0\n",
      "Mean Reward of that batch 43.291666666666664\n",
      "Average Reward of all training: 44.32561665650224\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  16 / 500\n",
      "Number of training episodes: 25\n",
      "Total reward: 1022.0\n",
      "Mean Reward of that batch 40.88\n",
      "Average Reward of all training: 44.11026561547085\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  17 / 500\n",
      "Number of training episodes: 18\n",
      "Total reward: 1035.0\n",
      "Mean Reward of that batch 57.5\n",
      "Average Reward of all training: 44.89789704985492\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  18 / 500\n",
      "Number of training episodes: 15\n",
      "Total reward: 1025.0\n",
      "Mean Reward of that batch 68.33333333333333\n",
      "Average Reward of all training: 46.19986573227039\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  19 / 500\n",
      "Number of training episodes: 16\n",
      "Total reward: 1048.0\n",
      "Mean Reward of that batch 65.5\n",
      "Average Reward of all training: 47.21566227267721\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  20 / 500\n",
      "Number of training episodes: 16\n",
      "Total reward: 1024.0\n",
      "Mean Reward of that batch 64.0\n",
      "Average Reward of all training: 48.05487915904335\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  21 / 500\n",
      "Number of training episodes: 14\n",
      "Total reward: 1069.0\n",
      "Mean Reward of that batch 76.35714285714286\n",
      "Average Reward of all training: 49.402606001809986\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  22 / 500\n",
      "Number of training episodes: 16\n",
      "Total reward: 1020.0\n",
      "Mean Reward of that batch 63.75\n",
      "Average Reward of all training: 50.05476027445499\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  23 / 500\n",
      "Number of training episodes: 16\n",
      "Total reward: 1041.0\n",
      "Mean Reward of that batch 65.0625\n",
      "Average Reward of all training: 50.70727069730477\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  24 / 500\n",
      "Number of training episodes: 15\n",
      "Total reward: 1056.0\n",
      "Mean Reward of that batch 70.4\n",
      "Average Reward of all training: 51.52780108491708\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  25 / 500\n",
      "Number of training episodes: 15\n",
      "Total reward: 1013.0\n",
      "Mean Reward of that batch 67.53333333333333\n",
      "Average Reward of all training: 52.16802237485373\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  26 / 500\n",
      "Number of training episodes: 13\n",
      "Total reward: 1048.0\n",
      "Mean Reward of that batch 80.61538461538461\n",
      "Average Reward of all training: 53.26215169179722\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  27 / 500\n",
      "Number of training episodes: 11\n",
      "Total reward: 1034.0\n",
      "Mean Reward of that batch 94.0\n",
      "Average Reward of all training: 54.77096088839732\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  28 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1195.0\n",
      "Mean Reward of that batch 132.77777777777777\n",
      "Average Reward of all training: 57.556918634446625\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  29 / 500\n",
      "Number of training episodes: 11\n",
      "Total reward: 1008.0\n",
      "Mean Reward of that batch 91.63636363636364\n",
      "Average Reward of all training: 58.7320719103748\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  30 / 500\n",
      "Number of training episodes: 11\n",
      "Total reward: 1094.0\n",
      "Mean Reward of that batch 99.45454545454545\n",
      "Average Reward of all training: 60.089487695180495\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  31 / 500\n",
      "Number of training episodes: 11\n",
      "Total reward: 1068.0\n",
      "Mean Reward of that batch 97.0909090909091\n",
      "Average Reward of all training: 61.28308193375238\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  32 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1041.0\n",
      "Mean Reward of that batch 115.66666666666667\n",
      "Average Reward of all training: 62.98256895665595\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  33 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1060.0\n",
      "Mean Reward of that batch 106.0\n",
      "Average Reward of all training: 64.28612747312093\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  34 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1015.0\n",
      "Mean Reward of that batch 101.5\n",
      "Average Reward of all training: 65.3806531356762\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  35 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1040.0\n",
      "Mean Reward of that batch 130.0\n",
      "Average Reward of all training: 67.22692018894259\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  36 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1046.0\n",
      "Mean Reward of that batch 116.22222222222223\n",
      "Average Reward of all training: 68.58790080097813\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  37 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1151.0\n",
      "Mean Reward of that batch 143.875\n",
      "Average Reward of all training: 70.62268726581655\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  38 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1059.0\n",
      "Mean Reward of that batch 132.375\n",
      "Average Reward of all training: 72.24774812724245\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  39 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1050.0\n",
      "Mean Reward of that batch 175.0\n",
      "Average Reward of all training: 74.88242125218494\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  40 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1059.0\n",
      "Mean Reward of that batch 176.5\n",
      "Average Reward of all training: 77.42286072088032\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  41 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1075.0\n",
      "Mean Reward of that batch 134.375\n",
      "Average Reward of all training: 78.81193728866373\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  42 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1026.0\n",
      "Mean Reward of that batch 171.0\n",
      "Average Reward of all training: 81.00689116274316\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  43 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1157.0\n",
      "Mean Reward of that batch 192.83333333333334\n",
      "Average Reward of all training: 83.60750609694293\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  44 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1044.0\n",
      "Mean Reward of that batch 149.14285714285714\n",
      "Average Reward of all training: 85.09694589344099\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  45 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1106.0\n",
      "Mean Reward of that batch 138.25\n",
      "Average Reward of all training: 86.27812487358675\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  46 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1017.0\n",
      "Mean Reward of that batch 169.5\n",
      "Average Reward of all training: 88.08729607198703\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  47 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1091.0\n",
      "Mean Reward of that batch 155.85714285714286\n",
      "Average Reward of all training: 89.52920770571376\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  48 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1005.0\n",
      "Mean Reward of that batch 167.5\n",
      "Average Reward of all training: 91.15359921184472\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  49 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1018.0\n",
      "Mean Reward of that batch 127.25\n",
      "Average Reward of all training: 91.89026045241931\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  50 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1125.0\n",
      "Mean Reward of that batch 187.5\n",
      "Average Reward of all training: 93.80245524337093\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  51 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1031.0\n",
      "Mean Reward of that batch 171.83333333333334\n",
      "Average Reward of all training: 95.33247246082117\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  52 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1153.0\n",
      "Mean Reward of that batch 192.16666666666666\n",
      "Average Reward of all training: 97.19466850324127\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  53 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1152.0\n",
      "Mean Reward of that batch 192.0\n",
      "Average Reward of all training: 98.98344834280276\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  54 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1175.0\n",
      "Mean Reward of that batch 195.83333333333334\n",
      "Average Reward of all training: 100.77696473151629\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  55 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 102.581019918216\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  56 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1132.0\n",
      "Mean Reward of that batch 188.66666666666666\n",
      "Average Reward of all training: 104.11826361015262\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  57 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1155.0\n",
      "Mean Reward of that batch 192.5\n",
      "Average Reward of all training: 105.66882038892187\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  58 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1053.0\n",
      "Mean Reward of that batch 175.5\n",
      "Average Reward of all training: 106.87280624428529\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  59 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1090.0\n",
      "Mean Reward of that batch 181.66666666666666\n",
      "Average Reward of all training: 108.14049879381717\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  60 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1009.0\n",
      "Mean Reward of that batch 168.16666666666666\n",
      "Average Reward of all training: 109.14093492503135\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  61 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 110.6304277951128\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  62 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1199.0\n",
      "Mean Reward of that batch 199.83333333333334\n",
      "Average Reward of all training: 112.06918433605183\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  63 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1084.0\n",
      "Mean Reward of that batch 135.5\n",
      "Average Reward of all training: 112.44110204500339\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  64 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1085.0\n",
      "Mean Reward of that batch 180.83333333333334\n",
      "Average Reward of all training: 113.50973065888353\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  65 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1085.0\n",
      "Mean Reward of that batch 120.55555555555556\n",
      "Average Reward of all training: 113.61812796498617\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  66 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 114.92694420794093\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  67 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 116.19669130931494\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  68 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1117.0\n",
      "Mean Reward of that batch 186.16666666666666\n",
      "Average Reward of all training: 117.22566153515835\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  69 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 118.42528962885171\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  70 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1123.0\n",
      "Mean Reward of that batch 187.16666666666666\n",
      "Average Reward of all training: 119.4073093008205\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  71 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1089.0\n",
      "Mean Reward of that batch 181.5\n",
      "Average Reward of all training: 120.28185424024556\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  72 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1161.0\n",
      "Mean Reward of that batch 193.5\n",
      "Average Reward of all training: 121.29877293135327\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  73 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1155.0\n",
      "Mean Reward of that batch 192.5\n",
      "Average Reward of all training: 122.27413220626623\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  74 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 123.32448177104642\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  75 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 124.34682201409913\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  76 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1115.0\n",
      "Mean Reward of that batch 159.28571428571428\n",
      "Average Reward of all training: 124.8065442808309\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  77 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1154.0\n",
      "Mean Reward of that batch 192.33333333333334\n",
      "Average Reward of all training: 125.68351556722705\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  78 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1158.0\n",
      "Mean Reward of that batch 193.0\n",
      "Average Reward of all training: 126.54654741892926\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  79 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1116.0\n",
      "Mean Reward of that batch 186.0\n",
      "Average Reward of all training: 127.29912276805675\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  80 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 128.20788373345604\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  81 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1138.0\n",
      "Mean Reward of that batch 189.66666666666666\n",
      "Average Reward of all training: 128.96663414003888\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  82 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1003.0\n",
      "Mean Reward of that batch 167.16666666666666\n",
      "Average Reward of all training: 129.43248819524166\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  83 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 130.28269918084115\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  84 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1067.0\n",
      "Mean Reward of that batch 177.83333333333334\n",
      "Average Reward of all training: 130.848778158847\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  85 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1010.0\n",
      "Mean Reward of that batch 126.25\n",
      "Average Reward of all training: 130.79467488639\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  86 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1149.0\n",
      "Mean Reward of that batch 191.5\n",
      "Average Reward of all training: 131.50055075980407\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  87 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1150.0\n",
      "Mean Reward of that batch 191.66666666666666\n",
      "Average Reward of all training: 132.19211531045764\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  88 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 132.962659454657\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  89 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1175.0\n",
      "Mean Reward of that batch 195.83333333333334\n",
      "Average Reward of all training: 133.66907152070954\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  90 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1173.0\n",
      "Mean Reward of that batch 195.5\n",
      "Average Reward of all training: 134.3560818371461\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  91 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1197.0\n",
      "Mean Reward of that batch 199.5\n",
      "Average Reward of all training: 135.07194906970494\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  92 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 135.77768875372988\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  93 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1152.0\n",
      "Mean Reward of that batch 192.0\n",
      "Average Reward of all training: 136.38222973487257\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  94 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1097.0\n",
      "Mean Reward of that batch 156.71428571428572\n",
      "Average Reward of all training: 136.59852820273866\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  95 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1014.0\n",
      "Mean Reward of that batch 126.75\n",
      "Average Reward of all training: 136.4948594848151\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  96 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1110.0\n",
      "Mean Reward of that batch 138.75\n",
      "Average Reward of all training: 136.51835053184828\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  97 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 137.1728005263653\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  98 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1193.0\n",
      "Mean Reward of that batch 198.83333333333334\n",
      "Average Reward of all training: 137.8019896366405\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  99 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1193.0\n",
      "Mean Reward of that batch 198.83333333333334\n",
      "Average Reward of all training: 138.418467855799\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  100 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 139.03428317724104\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  101 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1148.0\n",
      "Mean Reward of that batch 164.0\n",
      "Average Reward of all training: 139.28146849231786\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  102 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1157.0\n",
      "Mean Reward of that batch 192.83333333333334\n",
      "Average Reward of all training: 139.80648677507293\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  103 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 140.39088981609163\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  104 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 140.96405433709072\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  105 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1109.0\n",
      "Mean Reward of that batch 158.42857142857142\n",
      "Average Reward of all training: 141.13038307129528\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  106 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1172.0\n",
      "Mean Reward of that batch 195.33333333333334\n",
      "Average Reward of all training: 141.64173165867302\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  107 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 142.18713603569478\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  108 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 142.72244033166055\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  109 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 143.24792253045266\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  110 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 143.76385050744855\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  111 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 144.27048248485892\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  112 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1194.0\n",
      "Mean Reward of that batch 199.0\n",
      "Average Reward of all training: 144.75913889124408\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  113 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1147.0\n",
      "Mean Reward of that batch 163.85714285714286\n",
      "Average Reward of all training: 144.92814777589805\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  114 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1117.0\n",
      "Mean Reward of that batch 186.16666666666666\n",
      "Average Reward of all training: 145.28988916967674\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  115 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 145.76562926385344\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  116 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1122.0\n",
      "Mean Reward of that batch 187.0\n",
      "Average Reward of all training: 146.1210979770961\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  117 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 146.5816014131893\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  118 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1182.0\n",
      "Mean Reward of that batch 197.0\n",
      "Average Reward of all training: 147.0088759774843\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  119 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1040.0\n",
      "Mean Reward of that batch 173.33333333333334\n",
      "Average Reward of all training: 147.23008990484436\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  120 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1006.0\n",
      "Mean Reward of that batch 143.71428571428572\n",
      "Average Reward of all training: 147.20079153658972\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  121 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1148.0\n",
      "Mean Reward of that batch 164.0\n",
      "Average Reward of all training: 147.33962797017162\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  122 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1124.0\n",
      "Mean Reward of that batch 187.33333333333334\n",
      "Average Reward of all training: 147.6674452272467\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  123 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1098.0\n",
      "Mean Reward of that batch 183.0\n",
      "Average Reward of all training: 147.9547017701146\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  124 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1171.0\n",
      "Mean Reward of that batch 195.16666666666666\n",
      "Average Reward of all training: 148.3354434225062\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  125 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 148.74875987512613\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  126 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 149.15551574913306\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  127 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 149.55586601882493\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  128 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 149.94996081555286\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  129 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1086.0\n",
      "Mean Reward of that batch 155.14285714285714\n",
      "Average Reward of all training: 149.99021582584206\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  130 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1085.0\n",
      "Mean Reward of that batch 155.0\n",
      "Average Reward of all training: 150.02875262718172\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  131 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1111.0\n",
      "Mean Reward of that batch 158.71428571428572\n",
      "Average Reward of all training: 150.0950544064726\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  132 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1105.0\n",
      "Mean Reward of that batch 184.16666666666666\n",
      "Average Reward of all training: 150.35317268117106\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  133 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1062.0\n",
      "Mean Reward of that batch 177.0\n",
      "Average Reward of all training: 150.55352476627502\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  134 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 150.92252831279535\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  135 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 151.28606514010798\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  136 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1187.0\n",
      "Mean Reward of that batch 197.83333333333334\n",
      "Average Reward of all training: 151.62832446505817\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  137 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1136.0\n",
      "Mean Reward of that batch 142.0\n",
      "Average Reward of all training: 151.5580447244373\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  138 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1060.0\n",
      "Mean Reward of that batch 132.5\n",
      "Average Reward of all training: 151.41994295107182\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  139 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1132.0\n",
      "Mean Reward of that batch 188.66666666666666\n",
      "Average Reward of all training: 151.68790499219122\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  140 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1161.0\n",
      "Mean Reward of that batch 193.5\n",
      "Average Reward of all training: 151.98656281367556\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  141 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1097.0\n",
      "Mean Reward of that batch 182.83333333333334\n",
      "Average Reward of all training: 152.2053342358008\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  142 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1088.0\n",
      "Mean Reward of that batch 181.33333333333334\n",
      "Average Reward of all training: 152.41046099000877\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  143 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1085.0\n",
      "Mean Reward of that batch 180.83333333333334\n",
      "Average Reward of all training: 152.609222335067\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  144 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1190.0\n",
      "Mean Reward of that batch 198.33333333333334\n",
      "Average Reward of all training: 152.92675088366605\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  145 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 153.25139398102007\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  146 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 153.57158991265692\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  147 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 153.8874294370606\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  148 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 154.19900085978318\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  149 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 154.5063901157578\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  150 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 154.8096808483194\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  151 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 155.1089544850855\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  152 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 155.4042903108415\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  153 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1039.0\n",
      "Mean Reward of that batch 173.16666666666666\n",
      "Average Reward of all training: 155.5203842739515\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  154 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 155.80921294749726\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  155 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 156.09431479944888\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  156 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 156.37576149945244\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  157 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 156.65362289117567\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  158 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 156.92796705009226\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  159 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 157.1988603390854\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  160 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 157.46636746196612\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  161 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 157.7305515149974\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  162 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 157.99147403650974\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  163 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 158.24919505469066\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  164 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 158.5037731336255\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  165 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 158.7552654176641\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  166 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 159.0037276741842\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  167 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 159.24921433481782\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  168 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 159.4917785352058\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  169 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 159.7314721533407\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  170 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 159.96834584655633\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  171 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 160.20244908721975\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  172 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 160.43383019717777\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  173 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 160.66253638100912\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  174 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1158.0\n",
      "Mean Reward of that batch 193.0\n",
      "Average Reward of all training: 160.8483838730723\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  175 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1190.0\n",
      "Mean Reward of that batch 198.33333333333334\n",
      "Average Reward of all training: 161.06258358427377\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  176 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1146.0\n",
      "Mean Reward of that batch 191.0\n",
      "Average Reward of all training: 161.23268254118128\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  177 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1107.0\n",
      "Mean Reward of that batch 184.5\n",
      "Average Reward of all training: 161.36413631213506\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  178 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1151.0\n",
      "Mean Reward of that batch 191.83333333333334\n",
      "Average Reward of all training: 161.5353115762991\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  179 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1097.0\n",
      "Mean Reward of that batch 182.83333333333334\n",
      "Average Reward of all training: 161.65429493807022\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  180 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 161.86732663285872\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  181 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1095.0\n",
      "Mean Reward of that batch 182.5\n",
      "Average Reward of all training: 161.98131930339542\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  182 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1171.0\n",
      "Mean Reward of that batch 195.16666666666666\n",
      "Average Reward of all training: 162.16365637682\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  183 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 162.37041235290295\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  184 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1110.0\n",
      "Mean Reward of that batch 185.0\n",
      "Average Reward of all training: 162.49339924228937\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  185 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1035.0\n",
      "Mean Reward of that batch 129.375\n",
      "Average Reward of all training: 162.3143808680067\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  186 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1133.0\n",
      "Mean Reward of that batch 141.625\n",
      "Average Reward of all training: 162.20314763753356\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  187 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 162.40526984268044\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  188 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 162.60524181160235\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  189 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 162.80309767503303\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  190 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 162.99887084516445\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  191 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 163.19259403445676\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  192 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 163.38429927386065\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  193 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 163.5740179304728\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  194 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 163.7617807246456\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  195 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 163.9476177465705\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  196 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 164.1315584723533\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  197 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 164.31363177960023\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  198 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 164.49386596253154\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  199 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 164.67228874663942\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  200 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 164.84892730290622\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  201 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 165.02380826159825\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  202 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 165.19695772564972\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  203 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 165.36840128365145\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  204 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 165.5381640224571\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  205 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 165.7062705394207\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  206 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 165.8727449542779\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  207 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 166.03761092068234\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  208 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 166.20089163740982\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  209 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 166.36260985924042\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  210 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 166.52278790752973\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  211 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 166.68144768047983\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  212 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 166.83861066311908\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  213 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 166.99429793700116\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  214 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 167.148530189632\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  215 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 167.3013277236337\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  216 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 167.45271046565392\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  217 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 167.60269797502878\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  218 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 167.75130945220755\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  219 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 167.89856374694634\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  220 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 168.04447936627838\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  221 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 168.18907448226807\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  222 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 168.33236693955516\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  223 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 168.47437426269616\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  224 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 168.61511366330913\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  225 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 168.75460204702776\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  226 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 168.892856020271\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  227 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.02989189683367\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  228 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.16572570430372\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  229 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.30037319031112\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  230 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.43384982861411\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  231 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.56617082502703\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  232 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1175.0\n",
      "Mean Reward of that batch 195.83333333333334\n",
      "Average Reward of all training: 169.67939135308006\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  233 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.8095227206634\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  234 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1097.0\n",
      "Mean Reward of that batch 182.83333333333334\n",
      "Average Reward of all training: 169.86518003097393\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  235 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.9934133074379\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  236 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.12055986121993\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  237 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1053.0\n",
      "Mean Reward of that batch 131.625\n",
      "Average Reward of all training: 169.95813133859875\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  238 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1021.0\n",
      "Mean Reward of that batch 145.85714285714286\n",
      "Average Reward of all training: 169.85686668111364\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  239 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1020.0\n",
      "Mean Reward of that batch 145.71428571428572\n",
      "Average Reward of all training: 169.75585169798887\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  240 / 500\n",
      "Number of training episodes: 13\n",
      "Total reward: 1057.0\n",
      "Mean Reward of that batch 81.3076923076923\n",
      "Average Reward of all training: 169.3873177005293\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  241 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1199.0\n",
      "Mean Reward of that batch 199.83333333333334\n",
      "Average Reward of all training: 169.51364971560318\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  242 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.63962636967094\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  243 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.76456617884926\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  244 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.888481891231\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  245 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.011386046777\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  246 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.13329098154622\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  247 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.25420883182335\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  248 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.37415153814666\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  249 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.4931308492384\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  250 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.61115832584144\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  251 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.7282453444636\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  252 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.84440310103318\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  253 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.95964261446784\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  254 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.0739747301589\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  255 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.18741012337398\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  256 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1104.0\n",
      "Mean Reward of that batch 184.0\n",
      "Average Reward of all training: 171.23745930257957\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  257 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.3493758033477\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  258 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.4604247343425\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  259 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.5706161446346\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  260 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.6799599286937\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  261 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.78846582935003\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  262 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.8961434406884\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  263 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.0030022108759\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  264 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1176.0\n",
      "Mean Reward of that batch 196.0\n",
      "Average Reward of all training: 172.0938999297741\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  265 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1128.0\n",
      "Mean Reward of that batch 188.0\n",
      "Average Reward of all training: 172.15392294890702\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  266 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.25860744909912\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  267 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.3625077957317\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  268 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.46563276664315\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  269 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1125.0\n",
      "Mean Reward of that batch 187.5\n",
      "Average Reward of all training: 172.52152260765934\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  270 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.6232947461495\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  271 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1034.0\n",
      "Mean Reward of that batch 172.33333333333334\n",
      "Average Reward of all training: 172.62222477783652\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  272 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1043.0\n",
      "Mean Reward of that batch 149.0\n",
      "Average Reward of all training: 172.53537836321212\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  273 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.63598137287067\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  274 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.73585005399158\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  275 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.83499241743164\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  276 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.93341635794818\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  277 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.03112965629492\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  278 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.12813998127228\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  279 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.22445489173367\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  280 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1198.0\n",
      "Mean Reward of that batch 199.66666666666666\n",
      "Average Reward of all training: 173.31889136235847\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  281 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1196.0\n",
      "Mean Reward of that batch 199.33333333333334\n",
      "Average Reward of all training: 173.41146944766442\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  282 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1196.0\n",
      "Mean Reward of that batch 199.33333333333334\n",
      "Average Reward of all training: 173.50339095080508\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  283 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1032.0\n",
      "Mean Reward of that batch 129.0\n",
      "Average Reward of all training: 173.34613515239235\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  284 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.4399867891797\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  285 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1152.0\n",
      "Mean Reward of that batch 192.0\n",
      "Average Reward of all training: 173.505109642551\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  286 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1124.0\n",
      "Mean Reward of that batch 187.33333333333334\n",
      "Average Reward of all training: 173.55346007503624\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  287 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.64560829777133\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  288 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.73711660229296\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  289 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1197.0\n",
      "Mean Reward of that batch 199.5\n",
      "Average Reward of all training: 173.82626152754452\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  290 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.91651579813922\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  291 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.00614976446863\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  292 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.0951697995218\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  293 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1048.0\n",
      "Mean Reward of that batch 174.66666666666666\n",
      "Average Reward of all training: 174.09712030077486\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  294 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1113.0\n",
      "Mean Reward of that batch 159.0\n",
      "Average Reward of all training: 174.04576955145248\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  295 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1161.0\n",
      "Mean Reward of that batch 193.5\n",
      "Average Reward of all training: 174.11171609534588\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  296 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1102.0\n",
      "Mean Reward of that batch 157.42857142857142\n",
      "Average Reward of all training: 174.05535412012028\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  297 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1079.0\n",
      "Mean Reward of that batch 179.83333333333334\n",
      "Average Reward of all training: 174.07480859558564\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  298 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.16180588217762\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  299 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.24822124712017\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  300 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.33406050962978\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  301 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.41932941159115\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  302 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.50403361883755\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  303 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1197.0\n",
      "Mean Reward of that batch 199.5\n",
      "Average Reward of all training: 174.58652855738924\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  304 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.67012550292412\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  305 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1123.0\n",
      "Mean Reward of that batch 187.16666666666666\n",
      "Average Reward of all training: 174.71109776903478\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  306 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1178.0\n",
      "Mean Reward of that batch 196.33333333333334\n",
      "Average Reward of all training: 174.78175866957167\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  307 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1198.0\n",
      "Mean Reward of that batch 199.66666666666666\n",
      "Average Reward of all training: 174.8628170018098\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  308 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1181.0\n",
      "Mean Reward of that batch 196.83333333333334\n",
      "Average Reward of all training: 174.934149847042\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  309 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1199.0\n",
      "Mean Reward of that batch 199.83333333333334\n",
      "Average Reward of all training: 175.01472972887467\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  310 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.09532737491054\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  311 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1192.0\n",
      "Mean Reward of that batch 198.66666666666666\n",
      "Average Reward of all training: 175.1711194626654\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  312 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1135.0\n",
      "Mean Reward of that batch 189.16666666666666\n",
      "Average Reward of all training: 175.21597698575513\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  313 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.29515916790928\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  314 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.37383700495417\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  315 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.45201530017653\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  316 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.52969879606204\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  317 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.60689217525427\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  318 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.6836000614956\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  319 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.7598270205505\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  320 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.83557756111128\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  321 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.91085613568725\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  322 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.98566714147702\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  323 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.0600149212248\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  324 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.1339037640605\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  325 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.20733790632494\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  326 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.28032153237916\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  327 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.3528587753994\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  328 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.42495371815733\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  329 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1152.0\n",
      "Mean Reward of that batch 192.0\n",
      "Average Reward of all training: 176.47229428436356\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  330 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1189.0\n",
      "Mean Reward of that batch 198.16666666666666\n",
      "Average Reward of all training: 176.53803480673417\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  331 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.60891687680447\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  332 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.67937194645265\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  333 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.74940386252936\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  334 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1187.0\n",
      "Mean Reward of that batch 197.83333333333334\n",
      "Average Reward of all training: 176.8125293998671\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  335 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.88174573001675\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  336 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.9505500582012\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  337 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.01894605209378\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  338 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.08693733596334\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  339 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1097.0\n",
      "Mean Reward of that batch 182.83333333333334\n",
      "Average Reward of all training: 177.10388835660453\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  340 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1052.0\n",
      "Mean Reward of that batch 175.33333333333334\n",
      "Average Reward of all training: 177.09868084183017\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  341 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.16584013554916\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  342 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.23260668486043\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  343 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.29898392484625\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  344 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.36497525064613\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  345 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.43058401803555\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  346 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.49581354399498\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  347 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.56066710726876\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  348 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.62514794891456\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  349 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.68925927284315\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  350 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.75300424634932\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  351 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.81638600063323\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  352 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.87940763131326\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  353 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.94207219892994\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  354 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.00438272944143\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  355 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.0663422147106\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  356 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.12795361298387\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  357 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.18921984936208\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  358 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.2501438162633\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  359 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.31072837387816\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  360 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.37097635061738\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  361 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.43089054355198\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  362 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.49047371884603\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  363 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.54972861218255\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  364 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.60865792918204\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  365 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.66726434581443\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  366 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.725550508804\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  367 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.78351903602797\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  368 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.84117251690833\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  369 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.89851351279745\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  370 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.95554455735746\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  371 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.01226815693332\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  372 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.06868679092005\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  373 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.12480291212404\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  374 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.18061894711835\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  375 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.2361372965927\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  376 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.29136033569753\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  377 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.3462904143827\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  378 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.4009298577309\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  379 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1154.0\n",
      "Mean Reward of that batch 192.33333333333334\n",
      "Average Reward of all training: 179.43505229434197\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  380 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1025.0\n",
      "Mean Reward of that batch 146.42857142857142\n",
      "Average Reward of all training: 179.3481931341689\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  381 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1056.0\n",
      "Mean Reward of that batch 132.0\n",
      "Average Reward of all training: 179.22391966137582\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  382 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1071.0\n",
      "Mean Reward of that batch 133.875\n",
      "Average Reward of all training: 179.1052052120005\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  383 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1074.0\n",
      "Mean Reward of that batch 153.42857142857142\n",
      "Average Reward of all training: 179.0381643927226\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  384 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1080.0\n",
      "Mean Reward of that batch 180.0\n",
      "Average Reward of all training: 179.04066917294986\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  385 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1046.0\n",
      "Mean Reward of that batch 174.33333333333334\n",
      "Average Reward of all training: 179.0284423266132\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  386 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1064.0\n",
      "Mean Reward of that batch 152.0\n",
      "Average Reward of all training: 178.9584204553007\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  387 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1116.0\n",
      "Mean Reward of that batch 159.42857142857142\n",
      "Average Reward of all training: 178.90795572913348\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  388 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1018.0\n",
      "Mean Reward of that batch 169.66666666666666\n",
      "Average Reward of all training: 178.88413797381787\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  389 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1093.0\n",
      "Mean Reward of that batch 156.14285714285714\n",
      "Average Reward of all training: 178.82567709764572\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  390 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1026.0\n",
      "Mean Reward of that batch 171.0\n",
      "Average Reward of all training: 178.80561125893382\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  391 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1036.0\n",
      "Mean Reward of that batch 172.66666666666666\n",
      "Average Reward of all training: 178.78991063337816\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  392 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1041.0\n",
      "Mean Reward of that batch 173.5\n",
      "Average Reward of all training: 178.77641596339504\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  393 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1054.0\n",
      "Mean Reward of that batch 175.66666666666666\n",
      "Average Reward of all training: 178.76850311531174\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  394 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1174.0\n",
      "Mean Reward of that batch 195.66666666666666\n",
      "Average Reward of all training: 178.8113918552898\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  395 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.8650339012258\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  396 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.91840502773783\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  397 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1132.0\n",
      "Mean Reward of that batch 188.66666666666666\n",
      "Average Reward of all training: 178.94295984294925\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  398 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.99586697902225\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  399 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.0485089164182\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  400 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.1008876441271\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  401 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1171.0\n",
      "Mean Reward of that batch 195.16666666666666\n",
      "Average Reward of all training: 179.14095193096637\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  402 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.19284011024257\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  403 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1198.0\n",
      "Mean Reward of that batch 199.66666666666666\n",
      "Average Reward of all training: 179.24364365008478\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  404 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1192.0\n",
      "Mean Reward of that batch 198.66666666666666\n",
      "Average Reward of all training: 179.2917204397298\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  405 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1011.0\n",
      "Mean Reward of that batch 168.5\n",
      "Average Reward of all training: 179.26507421642182\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  406 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1152.0\n",
      "Mean Reward of that batch 192.0\n",
      "Average Reward of all training: 179.29644102869665\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  407 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.34730972395784\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  408 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.3979290628697\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  409 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.44830087445195\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  410 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.49842696988011\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  411 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.54830914270278\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  412 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.59794916905545\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  413 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.64734880787128\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  414 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.69650980108898\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  415 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.74543387385745\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  416 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.7941227347376\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  417 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.8425780759013\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  418 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.89080157332737\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  419 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.93879488699486\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  420 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.98655966107344\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  421 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.03409752411127\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  422 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.08141008922001\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  423 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.1284989542573\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  424 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.1753657020067\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  425 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.22201190035491\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  426 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.26843910246677\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  427 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.31464884695748\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  428 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.36064265806272\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  429 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.40642204580615\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  430 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.45198850616475\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  431 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.49734352123164\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  432 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.54248855937695\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  433 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.58742507540612\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  434 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.63215451071622\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  435 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.6766782934502\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  436 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.7209978386487\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  437 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.7651145484001\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  438 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.8090298119882\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  439 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.85274500603836\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  440 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1020.0\n",
      "Mean Reward of that batch 170.0\n",
      "Average Reward of all training: 180.82807967647918\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  441 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.8715534187094\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  442 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.91483044717384\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  443 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.95791209401997\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  444 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.0007996793938\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  445 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.04349451157492\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  446 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.0859978871095\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  447 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.12831109094148\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  448 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.17043539654205\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  449 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.21237206603752\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  450 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.2541223503352\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  451 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.295687489248\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  452 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.3370687116169\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  453 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.37826723543233\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  454 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.4192842679534\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  455 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.46012100582604\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  456 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.50077863519923\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  457 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.5412583318399\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  458 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.58156126124638\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  459 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.62168857876\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  460 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.66164142967574\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  461 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.70142094935107\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  462 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.74102826331352\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  463 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.78046448736683\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  464 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.81973072769577\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  465 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.85882808096954\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  466 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.89775763444388\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  467 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.93652046606175\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  468 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.97511764455308\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  469 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1011.0\n",
      "Mean Reward of that batch 168.5\n",
      "Average Reward of all training: 181.94638605042823\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  470 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.9847979950018\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  471 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.02304683153045\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  472 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.0611335967179\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  473 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.09905931850074\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  474 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.13682501614102\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  475 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.17443170031757\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  476 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 133.33333333333334\n",
      "Average Reward of all training: 182.07182435080708\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  477 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.10940962470477\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  478 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.1468376380422\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  479 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.18410937574984\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  480 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.22122581455037\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  481 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1014.0\n",
      "Mean Reward of that batch 169.0\n",
      "Average Reward of all training: 182.19373885859494\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  482 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.2306813090958\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  483 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.2674707887871\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  484 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.30410824583507\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  485 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.34059462058593\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  486 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.37693084564646\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  487 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.4131178459634\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  488 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.449156538902\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  489 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.48504783432347\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  490 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.52079263466157\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  491 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.55639183499832\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  492 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.59184632313855\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  493 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.62715697968392\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  494 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1197.0\n",
      "Mean Reward of that batch 199.5\n",
      "Average Reward of all training: 182.66131253235662\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  495 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 182.6963401838064\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  496 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1192.0\n",
      "Mean Reward of that batch 198.66666666666666\n",
      "Average Reward of all training: 182.72853842268316\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  497 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1198.0\n",
      "Mean Reward of that batch 199.66666666666666\n",
      "Average Reward of all training: 182.76261916361673\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  498 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1112.0\n",
      "Mean Reward of that batch 158.85714285714286\n",
      "Average Reward of all training: 182.7146161991459\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  499 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1113.0\n",
      "Mean Reward of that batch 159.0\n",
      "Average Reward of all training: 182.6670919181857\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  500 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1190.0\n",
      "Mean Reward of that batch 198.33333333333334\n",
      "Average Reward of all training: 182.69842440101598\n",
      "Max reward for a batch so far: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#===================\n",
    "# Training and Printing some stats\n",
    "#===================\n",
    "allRewards =[]\n",
    "total_rewards =0\n",
    "maximumRewardRecorded =0\n",
    "mean_reward_total =[]\n",
    "average_reward=[]\n",
    "training = True\n",
    "num_epochs = 500\n",
    "epoch = 1\n",
    "\n",
    "# saver\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if training:\n",
    "    while epoch < num_epochs +1:\n",
    "        states_mb, actions_mb, rewards_of_batch, discounted_rewards_mb, nb_episodes_mb = make_batch(1000)\n",
    "        # total rewards of the batch\n",
    "        total_reward_of_that_batch = np.sum(rewards_of_batch)\n",
    "        allRewards.append(total_reward_of_that_batch)\n",
    "\n",
    "        # calculate the mean reward of the batch\n",
    "        mean_reward_of_that_batch = np.divide(total_reward_of_that_batch, nb_episodes_mb)\n",
    "        mean_reward_total.append(mean_reward_of_that_batch)\n",
    "\n",
    "        # calculate the average reward of all training\n",
    "        average_reward_of_all_training = np.divide(np.sum(mean_reward_total), epoch)\n",
    "\n",
    "        # maximum reward recorded\n",
    "        max_reward_recorded = np.amax(allRewards)\n",
    "\n",
    "        print(\"===============================\")\n",
    "        print(\"Epoch: \", epoch, \"/\", num_epochs)\n",
    "        print(\"Number of training episodes: {}\".format(nb_episodes_mb))\n",
    "        print(\"Total reward: {}\".format(total_reward_of_that_batch, nb_episodes_mb))\n",
    "        print(\"Mean Reward of that batch {}\".format(mean_reward_of_that_batch))\n",
    "        print(\"Average Reward of all training: {}\".format(average_reward_of_all_training))\n",
    "        print(\"Max reward for a batch so far: {}\".format(maximumRewardRecorded))\n",
    "        \n",
    "        # Jieda note: update the ValueNetwork parameter, and make an estimate of Value function for each given St\n",
    "        feed_dict_value = {ValueNetwork.inputs:states_mb, ValueNetwork.target:discounted_rewards_mb}\n",
    "        _, loss = sess.run([ValueNetwork.train_opt, ValueNetwork.loss], feed_dict_value)\n",
    "        \n",
    "        # Now make a prediction of value function using the updated ValueNetwork parameters    \n",
    "        value_prediction = sess.run(ValueNetwork.value_estimate, {ValueNetwork.inputs: states_mb})\n",
    "\n",
    "        # Jieda note: compute the discounted total rewards minus baseline\n",
    "        # shape of discounted_rewards_mb should be an array of length (number of 4 tuples in that batch)\n",
    "        # shape of value_prediction should also be an array of length (number of 4 tuples in that batch)\n",
    "        # Note: 4 tuples are essentially samples (st,at,rt,st+1)\n",
    "        discounted_rewards_mb_minus_baseline = discounted_rewards_mb - value_prediction\n",
    "        \n",
    "        # Now update the Policy Network with a baseline that is the ValueNetwork Prediction\n",
    "        loss_,_ = sess.run([PolicyNetwork.loss,PolicyNetwork.train_opt], \\\n",
    "                feed_dict={PolicyNetwork.inputs: states_mb, PolicyNetwork.actions: actions_mb, PolicyNetwork.discounted_episode_rewards: discounted_rewards_mb_minus_baseline})\n",
    "\n",
    "        # update epoch\n",
    "        epoch +=1\n",
    "\n",
    "# plot the average episode reward vs epoch\n",
    "# episode reward is the total undiscounted reward for an episode\n",
    "plt.plot(range(0,len(mean_reward_total)), mean_reward_total)\n",
    "plt.savefig('./average_reward_vs_epoch_baseline.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the average reward over epochs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
