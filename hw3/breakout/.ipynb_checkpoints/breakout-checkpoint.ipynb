{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5844d0ebc584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gym'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "# Reference: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import gym\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "# choose a GPU card\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BreakoutNoFrameskip-v4\")\n",
    "obs = env.reset()\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 2D float array \"\"\"\n",
    "    image = image[35:195] # crop\n",
    "    image = image[::2,::2,0] # downsample by factor of 2\n",
    "    image[image == 144] = 0 # erase background (background type 1)\n",
    "    image[image == 109] = 0 # erase background (background type 2)\n",
    "    image[image != 0] = 1 # everything else just set to 1\n",
    "    return np.reshape(image.astype(np.float).ravel(), [80,80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Q network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is now exactly the same as Ghani's CNN settings\n",
    "# need to adjust to 80**)\n",
    "learning_rate=0.001\n",
    "state_size=[80,80,1]\n",
    "action_size=2\n",
    "n_outputs=2 # we are only using action 2 and 3 (RIGHT and LEFT)\n",
    "#\n",
    "input_height=80\n",
    "input_width=80\n",
    "input_channels=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Q network with input size of [80,80], and an output size of size of action space 2\n",
    "# Note that the action space is 4 with following meanings:\n",
    "# ['NOOP', 'FIRE', 'RIGHT', 'LEFT']\n",
    "# We will only be taking action 2 or 3\n",
    "class DQN(object):\n",
    "    def __init__(self, state_size, action_size, learning_rate, name=''):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            with tf.name_scope(\"inputs\"):\n",
    "                # Jieda note: state is preprocessd 80*80 array\n",
    "                self.inputs = tf.placeholder(tf.float32, [None,*state_size], name = \"inputs\")\n",
    "\n",
    "            with tf.name_scope(\"conv1\"):\n",
    "                self.conv1 = tf.layers.conv2d(\n",
    "                inputs=self.inputs, filters=32, kernel_size=[8, 8], strides=4,\n",
    "                kernel_initializer=tf.variance_scaling_initializer(scale=2),\n",
    "                padding=\"VALID\", activation=tf.nn.relu, use_bias=False, name='conv1')\n",
    "                \n",
    "                self.conv1_out = tf.nn.relu(self.conv1, name='conv1_out')\n",
    "             \n",
    "            with tf.name_scope(\"conv2\"):\n",
    "                \n",
    "                self.conv2 = tf.layers.conv2d(\n",
    "                inputs = self.conv1_out, filters=64,\n",
    "                kernel_size=[4,4], strides=[2,2],padding=\"VALID\",\n",
    "                kernel_initializer = tf.variance_scaling_initializer(scale=2),\n",
    "                activation=tf.nn.relu, use_bias=False, name='conv2')\n",
    "                \n",
    "                self.conv2_out = tf.nn.relu(self.conv2, name='conv2_out')\n",
    "            \n",
    "            with tf.name_scope(\"conv3\"):\n",
    "            \n",
    "                self.conv3 = tf.layers.conv2d(\n",
    "                inputs = self.conv2_out, filters=64,\n",
    "                 kernel_size=[3,3], strides=[1,1], padding=\"VALID\",\n",
    "                 kernel_initializer = tf.variance_scaling_initializer(scale=2),\n",
    "                 name = \"conv3\")\n",
    "                \n",
    "                self.conv3_out = tf.nn.relu(self.conv3, name='conv3_out')\n",
    "            \n",
    "            with tf.name_scope(\"flatten\"):\n",
    "                self.flatten = tf.contrib.layers.flatten(self.conv3_out)\n",
    "                \n",
    "\n",
    "            with tf.name_scope(\"fc1\"):\n",
    "                self.fc1 = tf.layers.dense(inputs=self.flatten,\n",
    "                                          units = 512, activation = tf.nn.relu,\n",
    "                                          kernel_initializer = tf.contrib.layers.xavier_initializer(), name = \"fc1\")\n",
    "            \n",
    "            with tf.name_scope(\"fc1\"):\n",
    "                self.fc2 = tf.layers.dense(inputs=self.flatten,\n",
    "                                          units = 512, activation = tf.nn.relu,\n",
    "                                          kernel_initializer = tf.contrib.layers.xavier_initializer(), name = \"fc2\")\n",
    "\n",
    "            with tf.name_scope(\"outputs\"):\n",
    "                self.outputs = tf.layers.dense(inputs = self.fc2,\n",
    "                                              units = action_size,\n",
    "                                              kernel_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "                                              activation = None)\n",
    "            # Output is the approximated Action Values Q(s,a), so we don't need any activation\n",
    "            \n",
    "    def get_outputs(self):\n",
    "\n",
    "        return self.outputs\n",
    "\n",
    "    def get_weights(self):\n",
    "\n",
    "        # give all the weights of that network\n",
    "        trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.name)\n",
    "        # create a dictionary to contain the values of the network weights\n",
    "        trainable_vars_by_name = {var.name[len(scope.name):]: var\n",
    "                                 for var in trainable_vars}\n",
    "\n",
    "        return trainable_vars_by_name\n",
    "        \n",
    "\n",
    "\n",
    "#             with tf.name_scope(\"loss\"):\n",
    "#                 self.cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = self.logits, labels =self.actions)\n",
    "#                 # Jieda noted: for baseline, we subtract the value_estimate_ from discounted_episode_rewards\n",
    "#                 self.weighted_negative_likelihoods = tf.multiply(self.cross_entropy, self.discounted_episode_rewards)\n",
    "#                 self.loss = tf.reduce_mean(self.weighted_negative_likelihoods)\n",
    "\n",
    "#             with tf.name_scope(\"train\"):\n",
    "#                 self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "#                 self.train_opt = self.optimizer.minimize(self.loss)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X_state=tf.placeholder(tf.float32,shape=[None,input_height, input_width,input_channels])\n",
    "# initialize the two Q network\n",
    "online_q = DQN(state_size, action_size, learning_rate, 'online_q_network')\n",
    "target_q = DQN(state_size, action_size, learning_rate, 'target_q_network')\n",
    "# get the output and weights from online q network\n",
    "online_q_values=online_q.get_outputs()\n",
    "online_q_weights=online_q.get_weights()\n",
    "# get the output and weights from target q network\n",
    "target_q_values=target_q.get_outputs()\n",
    "target_q_weights=target_q.get_weights()\n",
    "# # copy the weights of online network to target network\n",
    "# copy_ops = [target_q_wegiths.assign(online_q_weights[var_name]) for var_name, target_var in target_vars.items()]\n",
    "# #\n",
    "# copy_online_to_target = tf.group(*copy_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "# Use adam optimizer\n",
    "beta_1=0.9\n",
    "beta_2=0.999\n",
    "epsilon=1e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory_size=500000\n",
    "replay_memory = deque([],maxlen=replay_memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self,maxlen):\n",
    "        self.maxlen=maxlen\n",
    "        self.buf = \n",
    "\n",
    "def draw_samples_from_rb(batch_size):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Epsilon Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_min = 0.1\n",
    "eps_max = 1.0\n",
    "eps_decay_steps = 2000000\n",
    "def epsilon_greedy(q_values, step):\n",
    "    # Note: we gradually decrease epsilon, we explore more in the beginning, less towards later\n",
    "    epsilon = max(eps_min, eps_max-(eps_max-eps_min)*step/eps_decay_steps)\n",
    "    if np.random.rand()<epsilon:\n",
    "        return np.random.randint(n_outputs)\n",
    "    else:\n",
    "        return np.argmax(q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 4000000\n",
    "# In the very beginning, First have 10000 samples in the replay buffer\n",
    "training_start=10000\n",
    "# Before each training, we run 10 episodes and add those samples to replay buffer\n",
    "training_interval=4\n",
    "save_steps=1000\n",
    "copy_steps = 10000 # copy the online network parameters to target network every 10000 steps\n",
    "discount_rate=0.99\n",
    "skip_start=90\n",
    "batch_size=50\n",
    "iteration=0\n",
    "done=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
