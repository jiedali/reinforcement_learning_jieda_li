{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import gym\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "# choose a GPU card\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(object):\n",
    "\n",
    "    def __init__(self, state_size, action_size, learning_rate, name='PolicyNetwork'):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            with tf.name_scope(\"inputs\"):\n",
    "                self.inputs = tf.placeholder(tf.float32, [None,state_size], name = \"inputs_\")\n",
    "                # Jieda note: we are using sparse_softmax_cross_entropy_with_logits, so action is now a scaler (instead of a vector)\n",
    "                self.actions = tf.placeholder(tf.int32, [None,], name =\"actions\")\n",
    "                self.discounted_episode_rewards = tf.placeholder(tf.float32, [None,], name=\"discounted_episode_rewards_\")\n",
    "                # Jieda note: place holder for the ValueNetwork esitimated value\n",
    "                # Jieda note: following line is commented out, because feed the results from dis_sample_total_rewards - value_estimates\n",
    "                # directly to discounted_episode_rewards\n",
    "                # self.value_estimate = tf.placeholder(tf.float32, [None,], name=\"value_estimate_\")\n",
    "\n",
    "            with tf.name_scope(\"fc1\"):\n",
    "                self.fc1 = tf.layers.dense(inputs=self.inputs,\n",
    "                                          units = 256, activation = tf.nn.relu,\n",
    "                                          kernel_initializer = tf.contrib.layers.xavier_initializer(), name = \"fc1\")\n",
    "\n",
    "            with tf.name_scope(\"fc2\"):\n",
    "                self.fc2 = tf.layers.dense(inputs = self.fc1,\n",
    "                                           units = 256, activation = tf.nn.relu,\n",
    "                                           kernel_initializer = tf.contrib.layers.xavier_initializer(), name = 'fc2')\n",
    "\n",
    "            with tf.name_scope(\"logits\"):\n",
    "                self.logits = tf.layers.dense(inputs = self.fc2,\n",
    "                                              units = action_size,\n",
    "                                              kernel_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "                                              activation = None)\n",
    "            with tf.name_scope(\"softmax\"):\n",
    "                self.action_distribution = tf.nn.softmax(self.logits)\n",
    "\n",
    "            with tf.name_scope(\"loss\"):\n",
    "                self.cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = self.logits, labels =self.actions)\n",
    "                # Jieda noted: for baseline, we subtract the value_estimate_ from discounted_episode_rewards\n",
    "                self.weighted_negative_likelihoods = tf.multiply(self.cross_entropy, (self.discounted_episode_rewards))\n",
    "                self.loss = tf.reduce_mean(self.weighted_negative_likelihoods)\n",
    "\n",
    "            with tf.name_scope(\"train\"):\n",
    "                self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "                self.train_opt = self.optimizer.minimize(self.loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the value function network\n",
    "## input is the size of state, output is a single value\n",
    "class ValueNetwork(object):\n",
    "\n",
    "    def __init__(self, state_size, learning_rate, name='ValueNetwork'):\n",
    "        self.state_size = state_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            with tf.name_scope(\"inputs\"):\n",
    "                self.inputs = tf.placeholder(tf.float32, [None,state_size], name = \"inputs_\")\n",
    "                self.target = tf.placeholder(tf.float32, [None,], name = \"target\")\n",
    "\n",
    "            with tf.name_scope(\"value_fc1\"):\n",
    "                self.fc1 = tf.layers.dense(inputs=self.inputs,\n",
    "                                          units = 256, activation = tf.nn.relu,\n",
    "                                          kernel_initializer = tf.contrib.layers.xavier_initializer(), name = \"value_fc1\")\n",
    "\n",
    "            with tf.name_scope(\"value_fc2\"):\n",
    "                self.fc2 = tf.layers.dense(inputs = self.fc1,\n",
    "                                           units = 256, activation = tf.nn.relu,\n",
    "                                           kernel_initializer = tf.contrib.layers.xavier_initializer(), name = 'value_fc2')\n",
    "            with tf.name_scope(\"output\"):\n",
    "                self.output_layer = tf.layers.dense(\n",
    "                inputs=self.fc2,\n",
    "                units = 1,\n",
    "                activation = None,\n",
    "                kernel_initializer = tf.contrib.layers.xavier_initializer(), name = \"output\")\n",
    "            \n",
    "            \n",
    "            with tf.name_scope(\"loss\"):\n",
    "                self.value_estimate = tf.squeeze(self.output_layer)\n",
    "                self.loss = tf.squared_difference(self.value_estimate, self.target)\n",
    "\n",
    "            with tf.name_scope(\"train\"):\n",
    "                self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "                self.train_opt = self.optimizer.minimize(self.loss)\n",
    "    \n",
    "    # method to run prediction given a state\n",
    "    def predict(self, state, sess=None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        \n",
    "        return sess.run(self.value_estimate, {self.state: state})\n",
    "    \n",
    "    # method to update the Value neuron network parameters\n",
    "    def update(self, state, target, sess=None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        feed_dict = {self.state: state, self.target:target}\n",
    "        _, loss = sess.run([self.train_opt, self.loss], feed_dict)\n",
    "        \n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# environment parameters\n",
    "state_size = 4\n",
    "action_size = env.action_space.n\n",
    "possible_actions = np.identity(action_size,dtype=int).tolist()\n",
    "\n",
    "# training hyperparameters\n",
    "learning_rate = 0.002\n",
    "num_epochs = 500\n",
    "batch_size = 1000 # each 1 is a timestep (not an episode)\n",
    "\n",
    "\n",
    "## Helper function\n",
    "### calculates the discounted total rewards from current step onward\n",
    "\n",
    "def discount_rewards(r, gamma=0.95, normalization=False):\n",
    "    \"\"\"\n",
    "    computes the discounted rewards from time t onward for a given episode\n",
    "    length of r corresponds to the number of steps in an episode\n",
    "    discounted_r has the same length --> discounted rewards at each time step\n",
    "    \"\"\"\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    for i in reversed(range(0, len(r))):\n",
    "        running_add = running_add * gamma + r[i]\n",
    "        discounted_r[i] = running_add\n",
    "\n",
    "    if normalization:\n",
    "        mean = np.mean(discounted_r)\n",
    "        std = np.std(discounted_r)\n",
    "        discounted_r = (discounted_r - mean) / (std)\n",
    "\n",
    "    return discounted_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================\n",
    "# run policy\n",
    "#============================\n",
    "def make_batch(batch_size):\n",
    "\n",
    "    \"\"\"\n",
    "    We will run the policy and generate a bunch of episodes\n",
    "    We need to keep track of (st,at,rt,st+1) for each of the episode, those we will use for training\n",
    "    :param batch_size: number of episodes in a batch\n",
    "    :return: 3 list: states, actions, rewards of batch (each value is accumulated discounted total rewards)\n",
    "    \"\"\"\n",
    "    # initialize lists:\n",
    "\n",
    "    states, actions, rewards_of_episode, rewards_of_batch, discounted_rewards = [], [], [], [], []\n",
    "    # number of episode in batch\n",
    "    episode_num = 1\n",
    "\n",
    "    # Get a new state\n",
    "    state = env.reset()\n",
    "\n",
    "    while True:\n",
    "        # run state through policy and calculate action\n",
    "        action_probability_distribution = sess.run(PolicyNetwork.action_distribution, feed_dict={PolicyNetwork.inputs: state.reshape(1,state_size)})\n",
    "\n",
    "        # choose action\n",
    "        action = np.random.choice(range(action_probability_distribution.shape[1]), p=action_probability_distribution.ravel())\n",
    "\n",
    "        # perform action\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # the 3 lists here tracks the quantity for each episode\n",
    "        # the other 2 lists (rewards_of_batch and discounted_rewards, they are both list of list)\n",
    "        # they contain num_episode list and each list is the rewards of that episode of each time stamp\n",
    "        # rewards_of_batch is UNdiscounted, discounted_rewards is DISCOUNTED and counts from time t onwards\n",
    "        # in the calculation of loss function, we need the discounted_rewards\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards_of_episode.append(reward)\n",
    "\n",
    "        if done:\n",
    "            # if the entire episode is done\n",
    "\n",
    "            # if you have more than 1 episode in a batch, we track rewards of each episode in the batch\n",
    "            # this is undiscounted rewards, we WILL use this to do the plotting\n",
    "            rewards_of_batch.append(rewards_of_episode)\n",
    "\n",
    "            # disc_rwds_per_episode is a list with each element being the discounted reward from a time stamp t onward\n",
    "            disc_rwds_per_episode = discount_rewards(rewards_of_episode, gamma=0.99, normalization=True)\n",
    "            # discounted_rewards is a list of lenth (number of episode)\n",
    "            discounted_rewards.append(disc_rwds_per_episode)\n",
    "            #\n",
    "            if len(np.concatenate(rewards_of_batch)) > batch_size:\n",
    "                break\n",
    "            # reset the transition stores\n",
    "            rewards_of_episode = []\n",
    "            # add episode\n",
    "            episode_num += 1\n",
    "            # reset the state\n",
    "            state = env.reset()\n",
    "\n",
    "        else:\n",
    "            # if not done, the next_state become the current state\n",
    "            state = next_state\n",
    "\n",
    "    # Essentially, we will keep records of (state, action, rewards), need those for training!\n",
    "    return np.stack(np.array(states)), np.stack(np.array(actions)), np.concatenate(rewards_of_batch), np.concatenate(discounted_rewards),episode_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the graph\n",
    "tf.reset_default_graph()\n",
    "# tf.reset_default_graph()\n",
    "#==============================\n",
    "#  Initialize network and session\n",
    "#==============================\n",
    "# Instantiate the PolicyNetwork\n",
    "PolicyNetwork = PolicyNetwork(state_size, action_size, learning_rate)\n",
    "# Instantiate the ValueNetwork\n",
    "ValueNetwork = ValueNetwork(state_size, learning_rate)\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Epoch:  1 / 500\n",
      "Number of training episodes: 44\n",
      "Total reward: 1012.0\n",
      "Mean Reward of that batch 23.0\n",
      "Average Reward of all training: 23.0\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  2 / 500\n",
      "Number of training episodes: 44\n",
      "Total reward: 1036.0\n",
      "Mean Reward of that batch 23.545454545454547\n",
      "Average Reward of all training: 23.272727272727273\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  3 / 500\n",
      "Number of training episodes: 48\n",
      "Total reward: 1030.0\n",
      "Mean Reward of that batch 21.458333333333332\n",
      "Average Reward of all training: 22.66792929292929\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  4 / 500\n",
      "Number of training episodes: 44\n",
      "Total reward: 1016.0\n",
      "Mean Reward of that batch 23.09090909090909\n",
      "Average Reward of all training: 22.773674242424242\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  5 / 500\n",
      "Number of training episodes: 47\n",
      "Total reward: 1006.0\n",
      "Mean Reward of that batch 21.404255319148938\n",
      "Average Reward of all training: 22.499790457769183\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  6 / 500\n",
      "Number of training episodes: 49\n",
      "Total reward: 1013.0\n",
      "Mean Reward of that batch 20.6734693877551\n",
      "Average Reward of all training: 22.195403612766835\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  7 / 500\n",
      "Number of training episodes: 46\n",
      "Total reward: 1024.0\n",
      "Mean Reward of that batch 22.26086956521739\n",
      "Average Reward of all training: 22.20475589168834\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  8 / 500\n",
      "Number of training episodes: 44\n",
      "Total reward: 1038.0\n",
      "Mean Reward of that batch 23.59090909090909\n",
      "Average Reward of all training: 22.378025041590938\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  9 / 500\n",
      "Number of training episodes: 48\n",
      "Total reward: 1005.0\n",
      "Mean Reward of that batch 20.9375\n",
      "Average Reward of all training: 22.21796670363639\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  10 / 500\n",
      "Number of training episodes: 39\n",
      "Total reward: 1012.0\n",
      "Mean Reward of that batch 25.94871794871795\n",
      "Average Reward of all training: 22.591041828144547\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  11 / 500\n",
      "Number of training episodes: 46\n",
      "Total reward: 1001.0\n",
      "Mean Reward of that batch 21.76086956521739\n",
      "Average Reward of all training: 22.515571622423895\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  12 / 500\n",
      "Number of training episodes: 43\n",
      "Total reward: 1012.0\n",
      "Mean Reward of that batch 23.53488372093023\n",
      "Average Reward of all training: 22.600514297299423\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  13 / 500\n",
      "Number of training episodes: 43\n",
      "Total reward: 1035.0\n",
      "Mean Reward of that batch 24.069767441860463\n",
      "Average Reward of all training: 22.713533769957962\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  14 / 500\n",
      "Number of training episodes: 43\n",
      "Total reward: 1006.0\n",
      "Mean Reward of that batch 23.3953488372093\n",
      "Average Reward of all training: 22.762234846190204\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  15 / 500\n",
      "Number of training episodes: 45\n",
      "Total reward: 1009.0\n",
      "Mean Reward of that batch 22.42222222222222\n",
      "Average Reward of all training: 22.73956733792567\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  16 / 500\n",
      "Number of training episodes: 44\n",
      "Total reward: 1015.0\n",
      "Mean Reward of that batch 23.068181818181817\n",
      "Average Reward of all training: 22.760105742941676\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  17 / 500\n",
      "Number of training episodes: 41\n",
      "Total reward: 1001.0\n",
      "Mean Reward of that batch 24.414634146341463\n",
      "Average Reward of all training: 22.857430943141665\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  18 / 500\n",
      "Number of training episodes: 40\n",
      "Total reward: 1003.0\n",
      "Mean Reward of that batch 25.075\n",
      "Average Reward of all training: 22.98062922407824\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  19 / 500\n",
      "Number of training episodes: 46\n",
      "Total reward: 1006.0\n",
      "Mean Reward of that batch 21.869565217391305\n",
      "Average Reward of all training: 22.922152171094716\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  20 / 500\n",
      "Number of training episodes: 45\n",
      "Total reward: 1017.0\n",
      "Mean Reward of that batch 22.6\n",
      "Average Reward of all training: 22.906044562539982\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  21 / 500\n",
      "Number of training episodes: 44\n",
      "Total reward: 1008.0\n",
      "Mean Reward of that batch 22.90909090909091\n",
      "Average Reward of all training: 22.906189626661455\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  22 / 500\n",
      "Number of training episodes: 47\n",
      "Total reward: 1008.0\n",
      "Mean Reward of that batch 21.4468085106383\n",
      "Average Reward of all training: 22.839854121387674\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  23 / 500\n",
      "Number of training episodes: 48\n",
      "Total reward: 1001.0\n",
      "Mean Reward of that batch 20.854166666666668\n",
      "Average Reward of all training: 22.75351988422589\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  24 / 500\n",
      "Number of training episodes: 46\n",
      "Total reward: 1003.0\n",
      "Mean Reward of that batch 21.804347826086957\n",
      "Average Reward of all training: 22.7139710484701\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  25 / 500\n",
      "Number of training episodes: 51\n",
      "Total reward: 1008.0\n",
      "Mean Reward of that batch 19.764705882352942\n",
      "Average Reward of all training: 22.596000441825414\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  26 / 500\n",
      "Number of training episodes: 45\n",
      "Total reward: 1037.0\n",
      "Mean Reward of that batch 23.044444444444444\n",
      "Average Reward of all training: 22.613248288079994\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  27 / 500\n",
      "Number of training episodes: 42\n",
      "Total reward: 1037.0\n",
      "Mean Reward of that batch 24.69047619047619\n",
      "Average Reward of all training: 22.690182654835407\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  28 / 500\n",
      "Number of training episodes: 45\n",
      "Total reward: 1009.0\n",
      "Mean Reward of that batch 22.42222222222222\n",
      "Average Reward of all training: 22.680612639384936\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  29 / 500\n",
      "Number of training episodes: 42\n",
      "Total reward: 1014.0\n",
      "Mean Reward of that batch 24.142857142857142\n",
      "Average Reward of all training: 22.731034863642595\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  30 / 500\n",
      "Number of training episodes: 43\n",
      "Total reward: 1005.0\n",
      "Mean Reward of that batch 23.372093023255815\n",
      "Average Reward of all training: 22.75240346896304\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  31 / 500\n",
      "Number of training episodes: 49\n",
      "Total reward: 1030.0\n",
      "Mean Reward of that batch 21.020408163265305\n",
      "Average Reward of all training: 22.69653265265021\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  32 / 500\n",
      "Number of training episodes: 47\n",
      "Total reward: 1008.0\n",
      "Mean Reward of that batch 21.4468085106383\n",
      "Average Reward of all training: 22.657478773212336\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  33 / 500\n",
      "Number of training episodes: 39\n",
      "Total reward: 1019.0\n",
      "Mean Reward of that batch 26.128205128205128\n",
      "Average Reward of all training: 22.762652299121207\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  34 / 500\n",
      "Number of training episodes: 39\n",
      "Total reward: 1022.0\n",
      "Mean Reward of that batch 26.205128205128204\n",
      "Average Reward of all training: 22.863901590474352\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  35 / 500\n",
      "Number of training episodes: 49\n",
      "Total reward: 1021.0\n",
      "Mean Reward of that batch 20.836734693877553\n",
      "Average Reward of all training: 22.805982536285875\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  36 / 500\n",
      "Number of training episodes: 45\n",
      "Total reward: 1015.0\n",
      "Mean Reward of that batch 22.555555555555557\n",
      "Average Reward of all training: 22.799026231265586\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  37 / 500\n",
      "Number of training episodes: 47\n",
      "Total reward: 1017.0\n",
      "Mean Reward of that batch 21.638297872340427\n",
      "Average Reward of all training: 22.76765519453788\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  38 / 500\n",
      "Number of training episodes: 46\n",
      "Total reward: 1003.0\n",
      "Mean Reward of that batch 21.804347826086957\n",
      "Average Reward of all training: 22.74230500063128\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  39 / 500\n",
      "Number of training episodes: 45\n",
      "Total reward: 1038.0\n",
      "Mean Reward of that batch 23.066666666666666\n",
      "Average Reward of all training: 22.750621966427058\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  40 / 500\n",
      "Number of training episodes: 45\n",
      "Total reward: 1049.0\n",
      "Mean Reward of that batch 23.31111111111111\n",
      "Average Reward of all training: 22.76463419504416\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  41 / 500\n",
      "Number of training episodes: 44\n",
      "Total reward: 1026.0\n",
      "Mean Reward of that batch 23.318181818181817\n",
      "Average Reward of all training: 22.7781353565841\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  42 / 500\n",
      "Number of training episodes: 48\n",
      "Total reward: 1008.0\n",
      "Mean Reward of that batch 21.0\n",
      "Average Reward of all training: 22.735798800474956\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  43 / 500\n",
      "Number of training episodes: 44\n",
      "Total reward: 1007.0\n",
      "Mean Reward of that batch 22.886363636363637\n",
      "Average Reward of all training: 22.73930030828632\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  44 / 500\n",
      "Number of training episodes: 46\n",
      "Total reward: 1060.0\n",
      "Mean Reward of that batch 23.043478260869566\n",
      "Average Reward of all training: 22.746213443572305\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  45 / 500\n",
      "Number of training episodes: 45\n",
      "Total reward: 1040.0\n",
      "Mean Reward of that batch 23.11111111111111\n",
      "Average Reward of all training: 22.754322280628724\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  46 / 500\n",
      "Number of training episodes: 45\n",
      "Total reward: 1026.0\n",
      "Mean Reward of that batch 22.8\n",
      "Average Reward of all training: 22.7553152745281\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  47 / 500\n",
      "Number of training episodes: 41\n",
      "Total reward: 1023.0\n",
      "Mean Reward of that batch 24.951219512195124\n",
      "Average Reward of all training: 22.802036641286975\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  48 / 500\n",
      "Number of training episodes: 47\n",
      "Total reward: 1013.0\n",
      "Mean Reward of that batch 21.5531914893617\n",
      "Average Reward of all training: 22.776019033955194\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  49 / 500\n",
      "Number of training episodes: 42\n",
      "Total reward: 1006.0\n",
      "Mean Reward of that batch 23.952380952380953\n",
      "Average Reward of all training: 22.800026420045516\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  50 / 500\n",
      "Number of training episodes: 37\n",
      "Total reward: 1002.0\n",
      "Mean Reward of that batch 27.08108108108108\n",
      "Average Reward of all training: 22.885647513266225\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  51 / 500\n",
      "Number of training episodes: 47\n",
      "Total reward: 1011.0\n",
      "Mean Reward of that batch 21.51063829787234\n",
      "Average Reward of all training: 22.858686548258504\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  52 / 500\n",
      "Number of training episodes: 41\n",
      "Total reward: 1008.0\n",
      "Mean Reward of that batch 24.585365853658537\n",
      "Average Reward of all training: 22.891891919516198\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  53 / 500\n",
      "Number of training episodes: 41\n",
      "Total reward: 1021.0\n",
      "Mean Reward of that batch 24.902439024390244\n",
      "Average Reward of all training: 22.929826770551557\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  54 / 500\n",
      "Number of training episodes: 40\n",
      "Total reward: 1004.0\n",
      "Mean Reward of that batch 25.1\n",
      "Average Reward of all training: 22.97001516368949\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  55 / 500\n",
      "Number of training episodes: 45\n",
      "Total reward: 1008.0\n",
      "Mean Reward of that batch 22.4\n",
      "Average Reward of all training: 22.95965125162241\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  56 / 500\n",
      "Number of training episodes: 39\n",
      "Total reward: 1008.0\n",
      "Mean Reward of that batch 25.846153846153847\n",
      "Average Reward of all training: 23.011195940810467\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  57 / 500\n",
      "Number of training episodes: 40\n",
      "Total reward: 1005.0\n",
      "Mean Reward of that batch 25.125\n",
      "Average Reward of all training: 23.048280222550634\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  58 / 500\n",
      "Number of training episodes: 41\n",
      "Total reward: 1012.0\n",
      "Mean Reward of that batch 24.682926829268293\n",
      "Average Reward of all training: 23.076463784735424\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  59 / 500\n",
      "Number of training episodes: 46\n",
      "Total reward: 1059.0\n",
      "Mean Reward of that batch 23.02173913043478\n",
      "Average Reward of all training: 23.07553624822185\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  60 / 500\n",
      "Number of training episodes: 52\n",
      "Total reward: 1005.0\n",
      "Mean Reward of that batch 19.326923076923077\n",
      "Average Reward of all training: 23.013059362033538\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  61 / 500\n",
      "Number of training episodes: 43\n",
      "Total reward: 1003.0\n",
      "Mean Reward of that batch 23.325581395348838\n",
      "Average Reward of all training: 23.0181826740551\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  62 / 500\n",
      "Number of training episodes: 42\n",
      "Total reward: 1020.0\n",
      "Mean Reward of that batch 24.285714285714285\n",
      "Average Reward of all training: 23.038626732307666\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  63 / 500\n",
      "Number of training episodes: 43\n",
      "Total reward: 1015.0\n",
      "Mean Reward of that batch 23.6046511627907\n",
      "Average Reward of all training: 23.04761124707724\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  64 / 500\n",
      "Number of training episodes: 37\n",
      "Total reward: 1012.0\n",
      "Mean Reward of that batch 27.35135135135135\n",
      "Average Reward of all training: 23.114857186206525\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  65 / 500\n",
      "Number of training episodes: 45\n",
      "Total reward: 1011.0\n",
      "Mean Reward of that batch 22.466666666666665\n",
      "Average Reward of all training: 23.10488502436745\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  66 / 500\n",
      "Number of training episodes: 42\n",
      "Total reward: 1039.0\n",
      "Mean Reward of that batch 24.738095238095237\n",
      "Average Reward of all training: 23.129630633666356\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  67 / 500\n",
      "Number of training episodes: 46\n",
      "Total reward: 1019.0\n",
      "Mean Reward of that batch 22.152173913043477\n",
      "Average Reward of all training: 23.1150417273884\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  68 / 500\n",
      "Number of training episodes: 42\n",
      "Total reward: 1016.0\n",
      "Mean Reward of that batch 24.19047619047619\n",
      "Average Reward of all training: 23.130856940080868\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  69 / 500\n",
      "Number of training episodes: 40\n",
      "Total reward: 1023.0\n",
      "Mean Reward of that batch 25.575\n",
      "Average Reward of all training: 23.166279303268105\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  70 / 500\n",
      "Number of training episodes: 34\n",
      "Total reward: 1023.0\n",
      "Mean Reward of that batch 30.08823529411765\n",
      "Average Reward of all training: 23.265164388851666\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  71 / 500\n",
      "Number of training episodes: 37\n",
      "Total reward: 1023.0\n",
      "Mean Reward of that batch 27.64864864864865\n",
      "Average Reward of all training: 23.326903603778387\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  72 / 500\n",
      "Number of training episodes: 44\n",
      "Total reward: 1011.0\n",
      "Mean Reward of that batch 22.977272727272727\n",
      "Average Reward of all training: 23.322047619382474\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  73 / 500\n",
      "Number of training episodes: 36\n",
      "Total reward: 1024.0\n",
      "Mean Reward of that batch 28.444444444444443\n",
      "Average Reward of all training: 23.392217438903867\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  74 / 500\n",
      "Number of training episodes: 44\n",
      "Total reward: 1015.0\n",
      "Mean Reward of that batch 23.068181818181817\n",
      "Average Reward of all training: 23.38783857916438\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  75 / 500\n",
      "Number of training episodes: 37\n",
      "Total reward: 1015.0\n",
      "Mean Reward of that batch 27.43243243243243\n",
      "Average Reward of all training: 23.441766497207954\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  76 / 500\n",
      "Number of training episodes: 40\n",
      "Total reward: 1027.0\n",
      "Mean Reward of that batch 25.675\n",
      "Average Reward of all training: 23.47115114856048\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  77 / 500\n",
      "Number of training episodes: 45\n",
      "Total reward: 1020.0\n",
      "Mean Reward of that batch 22.666666666666668\n",
      "Average Reward of all training: 23.460703298146278\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  78 / 500\n",
      "Number of training episodes: 43\n",
      "Total reward: 1019.0\n",
      "Mean Reward of that batch 23.697674418604652\n",
      "Average Reward of all training: 23.463741389434205\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  79 / 500\n",
      "Number of training episodes: 41\n",
      "Total reward: 1064.0\n",
      "Mean Reward of that batch 25.951219512195124\n",
      "Average Reward of all training: 23.49522845427928\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  80 / 500\n",
      "Number of training episodes: 39\n",
      "Total reward: 1002.0\n",
      "Mean Reward of that batch 25.692307692307693\n",
      "Average Reward of all training: 23.522691944754637\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  81 / 500\n",
      "Number of training episodes: 30\n",
      "Total reward: 1014.0\n",
      "Mean Reward of that batch 33.8\n",
      "Average Reward of all training: 23.649572291115692\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  82 / 500\n",
      "Number of training episodes: 31\n",
      "Total reward: 1020.0\n",
      "Mean Reward of that batch 32.903225806451616\n",
      "Average Reward of all training: 23.762421724229544\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  83 / 500\n",
      "Number of training episodes: 30\n",
      "Total reward: 1006.0\n",
      "Mean Reward of that batch 33.53333333333333\n",
      "Average Reward of all training: 23.880143550845254\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  84 / 500\n",
      "Number of training episodes: 35\n",
      "Total reward: 1013.0\n",
      "Mean Reward of that batch 28.942857142857143\n",
      "Average Reward of all training: 23.940413950750155\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  85 / 500\n",
      "Number of training episodes: 39\n",
      "Total reward: 1002.0\n",
      "Mean Reward of that batch 25.692307692307693\n",
      "Average Reward of all training: 23.961024465356715\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  86 / 500\n",
      "Number of training episodes: 37\n",
      "Total reward: 1085.0\n",
      "Mean Reward of that batch 29.324324324324323\n",
      "Average Reward of all training: 24.023388417205176\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  87 / 500\n",
      "Number of training episodes: 37\n",
      "Total reward: 1039.0\n",
      "Mean Reward of that batch 28.08108108108108\n",
      "Average Reward of all training: 24.070028562766968\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  88 / 500\n",
      "Number of training episodes: 36\n",
      "Total reward: 1019.0\n",
      "Mean Reward of that batch 28.305555555555557\n",
      "Average Reward of all training: 24.118159551321387\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  89 / 500\n",
      "Number of training episodes: 34\n",
      "Total reward: 1013.0\n",
      "Mean Reward of that batch 29.794117647058822\n",
      "Average Reward of all training: 24.181934361385853\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  90 / 500\n",
      "Number of training episodes: 33\n",
      "Total reward: 1004.0\n",
      "Mean Reward of that batch 30.424242424242426\n",
      "Average Reward of all training: 24.251293339862038\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  91 / 500\n",
      "Number of training episodes: 38\n",
      "Total reward: 1007.0\n",
      "Mean Reward of that batch 26.5\n",
      "Average Reward of all training: 24.276004402061357\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  92 / 500\n",
      "Number of training episodes: 36\n",
      "Total reward: 1007.0\n",
      "Mean Reward of that batch 27.97222222222222\n",
      "Average Reward of all training: 24.316180682715277\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  93 / 500\n",
      "Number of training episodes: 30\n",
      "Total reward: 1005.0\n",
      "Mean Reward of that batch 33.5\n",
      "Average Reward of all training: 24.414931428062427\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  94 / 500\n",
      "Number of training episodes: 33\n",
      "Total reward: 1011.0\n",
      "Mean Reward of that batch 30.636363636363637\n",
      "Average Reward of all training: 24.481116877086905\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  95 / 500\n",
      "Number of training episodes: 30\n",
      "Total reward: 1008.0\n",
      "Mean Reward of that batch 33.6\n",
      "Average Reward of all training: 24.57710512048599\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  96 / 500\n",
      "Number of training episodes: 34\n",
      "Total reward: 1011.0\n",
      "Mean Reward of that batch 29.735294117647058\n",
      "Average Reward of all training: 24.63083625587308\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  97 / 500\n",
      "Number of training episodes: 34\n",
      "Total reward: 1010.0\n",
      "Mean Reward of that batch 29.705882352941178\n",
      "Average Reward of all training: 24.683156318729452\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  98 / 500\n",
      "Number of training episodes: 33\n",
      "Total reward: 1016.0\n",
      "Mean Reward of that batch 30.78787878787879\n",
      "Average Reward of all training: 24.745449405149344\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  99 / 500\n",
      "Number of training episodes: 27\n",
      "Total reward: 1026.0\n",
      "Mean Reward of that batch 38.0\n",
      "Average Reward of all training: 24.87933375459228\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  100 / 500\n",
      "Number of training episodes: 31\n",
      "Total reward: 1009.0\n",
      "Mean Reward of that batch 32.54838709677419\n",
      "Average Reward of all training: 24.9560242880141\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  101 / 500\n",
      "Number of training episodes: 25\n",
      "Total reward: 1019.0\n",
      "Mean Reward of that batch 40.76\n",
      "Average Reward of all training: 25.11249929506347\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  102 / 500\n",
      "Number of training episodes: 25\n",
      "Total reward: 1004.0\n",
      "Mean Reward of that batch 40.16\n",
      "Average Reward of all training: 25.26002381177853\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  103 / 500\n",
      "Number of training episodes: 23\n",
      "Total reward: 1082.0\n",
      "Mean Reward of that batch 47.04347826086956\n",
      "Average Reward of all training: 25.47151366079883\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  104 / 500\n",
      "Number of training episodes: 25\n",
      "Total reward: 1004.0\n",
      "Mean Reward of that batch 40.16\n",
      "Average Reward of all training: 25.61274910636807\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  105 / 500\n",
      "Number of training episodes: 28\n",
      "Total reward: 1018.0\n",
      "Mean Reward of that batch 36.357142857142854\n",
      "Average Reward of all training: 25.715076665899257\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  106 / 500\n",
      "Number of training episodes: 27\n",
      "Total reward: 1003.0\n",
      "Mean Reward of that batch 37.148148148148145\n",
      "Average Reward of all training: 25.822935830826136\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  107 / 500\n",
      "Number of training episodes: 24\n",
      "Total reward: 1039.0\n",
      "Mean Reward of that batch 43.291666666666664\n",
      "Average Reward of all training: 25.986194997516233\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  108 / 500\n",
      "Number of training episodes: 24\n",
      "Total reward: 1017.0\n",
      "Mean Reward of that batch 42.375\n",
      "Average Reward of all training: 26.137943191983677\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  109 / 500\n",
      "Number of training episodes: 26\n",
      "Total reward: 1054.0\n",
      "Mean Reward of that batch 40.53846153846154\n",
      "Average Reward of all training: 26.270058039199068\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  110 / 500\n",
      "Number of training episodes: 27\n",
      "Total reward: 1013.0\n",
      "Mean Reward of that batch 37.51851851851852\n",
      "Average Reward of all training: 26.372316770829247\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  111 / 500\n",
      "Number of training episodes: 19\n",
      "Total reward: 1040.0\n",
      "Mean Reward of that batch 54.73684210526316\n",
      "Average Reward of all training: 26.627853035103428\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  112 / 500\n",
      "Number of training episodes: 22\n",
      "Total reward: 1060.0\n",
      "Mean Reward of that batch 48.18181818181818\n",
      "Average Reward of all training: 26.82029915248481\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  113 / 500\n",
      "Number of training episodes: 18\n",
      "Total reward: 1015.0\n",
      "Mean Reward of that batch 56.388888888888886\n",
      "Average Reward of all training: 27.0819680882052\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  114 / 500\n",
      "Number of training episodes: 21\n",
      "Total reward: 1031.0\n",
      "Mean Reward of that batch 49.095238095238095\n",
      "Average Reward of all training: 27.275066947916013\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  115 / 500\n",
      "Number of training episodes: 19\n",
      "Total reward: 1006.0\n",
      "Mean Reward of that batch 52.94736842105263\n",
      "Average Reward of all training: 27.498304352030246\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  116 / 500\n",
      "Number of training episodes: 16\n",
      "Total reward: 1028.0\n",
      "Mean Reward of that batch 64.25\n",
      "Average Reward of all training: 27.815129314512742\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  117 / 500\n",
      "Number of training episodes: 20\n",
      "Total reward: 1066.0\n",
      "Mean Reward of that batch 53.3\n",
      "Average Reward of all training: 28.03294872208101\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  118 / 500\n",
      "Number of training episodes: 18\n",
      "Total reward: 1081.0\n",
      "Mean Reward of that batch 60.05555555555556\n",
      "Average Reward of all training: 28.30432674609351\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  119 / 500\n",
      "Number of training episodes: 14\n",
      "Total reward: 1031.0\n",
      "Mean Reward of that batch 73.64285714285714\n",
      "Average Reward of all training: 28.685322799847825\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  120 / 500\n",
      "Number of training episodes: 17\n",
      "Total reward: 1089.0\n",
      "Mean Reward of that batch 64.05882352941177\n",
      "Average Reward of all training: 28.98010197259419\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  121 / 500\n",
      "Number of training episodes: 17\n",
      "Total reward: 1066.0\n",
      "Mean Reward of that batch 62.705882352941174\n",
      "Average Reward of all training: 29.25882743028301\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  122 / 500\n",
      "Number of training episodes: 14\n",
      "Total reward: 1006.0\n",
      "Mean Reward of that batch 71.85714285714286\n",
      "Average Reward of all training: 29.6079939501753\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  123 / 500\n",
      "Number of training episodes: 14\n",
      "Total reward: 1040.0\n",
      "Mean Reward of that batch 74.28571428571429\n",
      "Average Reward of all training: 29.971227448838217\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  124 / 500\n",
      "Number of training episodes: 14\n",
      "Total reward: 1011.0\n",
      "Mean Reward of that batch 72.21428571428571\n",
      "Average Reward of all training: 30.31189727355957\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  125 / 500\n",
      "Number of training episodes: 15\n",
      "Total reward: 1040.0\n",
      "Mean Reward of that batch 69.33333333333333\n",
      "Average Reward of all training: 30.624068762037762\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  126 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1046.0\n",
      "Mean Reward of that batch 104.6\n",
      "Average Reward of all training: 31.211179327418414\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  127 / 500\n",
      "Number of training episodes: 11\n",
      "Total reward: 1016.0\n",
      "Mean Reward of that batch 92.36363636363636\n",
      "Average Reward of all training: 31.692694737152415\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  128 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1017.0\n",
      "Mean Reward of that batch 113.0\n",
      "Average Reward of all training: 32.32790805951841\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  129 / 500\n",
      "Number of training episodes: 11\n",
      "Total reward: 1146.0\n",
      "Mean Reward of that batch 104.18181818181819\n",
      "Average Reward of all training: 32.884915114730035\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  130 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1077.0\n",
      "Mean Reward of that batch 107.7\n",
      "Average Reward of all training: 33.46041576769365\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  131 / 500\n",
      "Number of training episodes: 13\n",
      "Total reward: 1064.0\n",
      "Mean Reward of that batch 81.84615384615384\n",
      "Average Reward of all training: 33.829772546918534\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  132 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1033.0\n",
      "Mean Reward of that batch 103.3\n",
      "Average Reward of all training: 34.35606214883582\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  133 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1106.0\n",
      "Mean Reward of that batch 110.6\n",
      "Average Reward of all training: 34.929324839446075\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  134 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1095.0\n",
      "Mean Reward of that batch 109.5\n",
      "Average Reward of all training: 35.4858224152711\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  135 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1061.0\n",
      "Mean Reward of that batch 117.88888888888889\n",
      "Average Reward of all training: 36.09621550026086\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  136 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1071.0\n",
      "Mean Reward of that batch 133.875\n",
      "Average Reward of all training: 36.815177150994245\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  137 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1198.0\n",
      "Mean Reward of that batch 149.75\n",
      "Average Reward of all training: 37.63951892361472\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  138 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1135.0\n",
      "Mean Reward of that batch 189.16666666666666\n",
      "Average Reward of all training: 38.73754173334699\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  139 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1039.0\n",
      "Mean Reward of that batch 129.875\n",
      "Average Reward of all training: 39.393206900732984\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  140 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1077.0\n",
      "Mean Reward of that batch 179.5\n",
      "Average Reward of all training: 40.39396970858489\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  141 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1047.0\n",
      "Mean Reward of that batch 116.33333333333333\n",
      "Average Reward of all training: 40.932546755568914\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  142 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1125.0\n",
      "Mean Reward of that batch 160.71428571428572\n",
      "Average Reward of all training: 41.77608012851763\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  143 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1026.0\n",
      "Mean Reward of that batch 128.25\n",
      "Average Reward of all training: 42.38079285489163\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  144 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1060.0\n",
      "Mean Reward of that batch 106.0\n",
      "Average Reward of all training: 42.822592904510444\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  145 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1158.0\n",
      "Mean Reward of that batch 193.0\n",
      "Average Reward of all training: 43.8582991603414\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  146 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1134.0\n",
      "Mean Reward of that batch 189.0\n",
      "Average Reward of all training: 44.8524203989692\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  147 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1157.0\n",
      "Mean Reward of that batch 192.83333333333334\n",
      "Average Reward of all training: 45.85909327607372\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  148 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1029.0\n",
      "Mean Reward of that batch 171.5\n",
      "Average Reward of all training: 46.708018321505655\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  149 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1109.0\n",
      "Mean Reward of that batch 158.42857142857142\n",
      "Average Reward of all training: 47.457820691351735\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  150 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1128.0\n",
      "Mean Reward of that batch 188.0\n",
      "Average Reward of all training: 48.394768553409385\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  151 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1079.0\n",
      "Mean Reward of that batch 179.83333333333334\n",
      "Average Reward of all training: 49.26522262479961\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  152 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1131.0\n",
      "Mean Reward of that batch 188.5\n",
      "Average Reward of all training: 50.181240897004876\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  153 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1174.0\n",
      "Mean Reward of that batch 195.66666666666666\n",
      "Average Reward of all training: 51.1321260327543\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  154 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1056.0\n",
      "Mean Reward of that batch 176.0\n",
      "Average Reward of all training: 51.94295638319096\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  155 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1091.0\n",
      "Mean Reward of that batch 181.83333333333334\n",
      "Average Reward of all training: 52.78095881512736\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  156 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1172.0\n",
      "Mean Reward of that batch 167.42857142857142\n",
      "Average Reward of all training: 53.515879408803286\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  157 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1040.0\n",
      "Mean Reward of that batch 173.33333333333334\n",
      "Average Reward of all training: 54.279047905137865\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  158 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1148.0\n",
      "Mean Reward of that batch 191.33333333333334\n",
      "Average Reward of all training: 55.14648009139227\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  159 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1048.0\n",
      "Mean Reward of that batch 174.66666666666666\n",
      "Average Reward of all training: 55.89817937802921\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  160 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1066.0\n",
      "Mean Reward of that batch 177.66666666666666\n",
      "Average Reward of all training: 56.659232423583205\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  161 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1172.0\n",
      "Mean Reward of that batch 167.42857142857142\n",
      "Average Reward of all training: 57.34724074038437\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  162 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1089.0\n",
      "Mean Reward of that batch 121.0\n",
      "Average Reward of all training: 57.74015900741903\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  163 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1172.0\n",
      "Mean Reward of that batch 195.33333333333334\n",
      "Average Reward of all training: 58.584288911259\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  164 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1197.0\n",
      "Mean Reward of that batch 199.5\n",
      "Average Reward of all training: 59.44353105204401\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  165 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1047.0\n",
      "Mean Reward of that batch 174.5\n",
      "Average Reward of all training: 60.14084298506192\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  166 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1197.0\n",
      "Mean Reward of that batch 171.0\n",
      "Average Reward of all training: 60.80866923213986\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  167 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 171.42857142857142\n",
      "Average Reward of all training: 61.471063856070586\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  168 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1196.0\n",
      "Mean Reward of that batch 199.33333333333334\n",
      "Average Reward of all training: 62.29167260295906\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  169 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 63.106514776906046\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  170 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1047.0\n",
      "Mean Reward of that batch 149.57142857142858\n",
      "Average Reward of all training: 63.61513191687383\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  171 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1080.0\n",
      "Mean Reward of that batch 180.0\n",
      "Average Reward of all training: 64.29574518051784\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  172 / 500\n",
      "Number of training episodes: 12\n",
      "Total reward: 1005.0\n",
      "Mean Reward of that batch 83.75\n",
      "Average Reward of all training: 64.40885131318925\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  173 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1104.0\n",
      "Mean Reward of that batch 184.0\n",
      "Average Reward of all training: 65.10012962929798\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  174 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1161.0\n",
      "Mean Reward of that batch 193.5\n",
      "Average Reward of all training: 65.83805991878478\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  175 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1132.0\n",
      "Mean Reward of that batch 188.66666666666666\n",
      "Average Reward of all training: 66.53993767162981\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  176 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 67.29823348031374\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  177 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1165.0\n",
      "Mean Reward of that batch 194.16666666666666\n",
      "Average Reward of all training: 68.01500428927618\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  178 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 68.75649302922406\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  179 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1012.0\n",
      "Mean Reward of that batch 126.5\n",
      "Average Reward of all training: 69.0790824536418\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  180 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1073.0\n",
      "Mean Reward of that batch 178.83333333333334\n",
      "Average Reward of all training: 69.68882829186232\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  181 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1055.0\n",
      "Mean Reward of that batch 131.875\n",
      "Average Reward of all training: 70.03239830129954\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  182 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1036.0\n",
      "Mean Reward of that batch 172.66666666666666\n",
      "Average Reward of all training: 70.5963228527576\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  183 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1080.0\n",
      "Mean Reward of that batch 180.0\n",
      "Average Reward of all training: 71.19415715410865\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  184 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 71.8941889087059\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  185 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 72.58665275244262\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  186 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 73.27167074839723\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  187 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1105.0\n",
      "Mean Reward of that batch 184.16666666666666\n",
      "Average Reward of all training: 73.86469211694413\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  188 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1151.0\n",
      "Mean Reward of that batch 191.83333333333334\n",
      "Average Reward of all training: 74.49218488937173\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  189 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 75.15624740318458\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  190 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 75.81331978527308\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  191 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 76.46351182828212\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  192 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 77.10693103750981\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  193 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 77.7436826901652\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  194 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1196.0\n",
      "Mean Reward of that batch 199.33333333333334\n",
      "Average Reward of all training: 78.37043346667637\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  195 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1063.0\n",
      "Mean Reward of that batch 151.85714285714286\n",
      "Average Reward of all training: 78.74728838662749\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  196 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 79.36592467036918\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  197 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 79.97828038270234\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  198 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 80.5844506837998\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  199 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1013.0\n",
      "Mean Reward of that batch 168.83333333333334\n",
      "Average Reward of all training: 81.02791240565675\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  200 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1055.0\n",
      "Mean Reward of that batch 117.22222222222223\n",
      "Average Reward of all training: 81.20888395473958\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  201 / 500\n",
      "Number of training episodes: 25\n",
      "Total reward: 1026.0\n",
      "Mean Reward of that batch 41.04\n",
      "Average Reward of all training: 81.0090387609349\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  202 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1002.0\n",
      "Mean Reward of that batch 125.25\n",
      "Average Reward of all training: 81.22805342053424\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  203 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1108.0\n",
      "Mean Reward of that batch 158.28571428571428\n",
      "Average Reward of all training: 81.60764780903266\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  204 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1061.0\n",
      "Mean Reward of that batch 132.625\n",
      "Average Reward of all training: 81.8577328687923\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  205 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1010.0\n",
      "Mean Reward of that batch 126.25\n",
      "Average Reward of all training: 82.07428051333478\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  206 / 500\n",
      "Number of training episodes: 11\n",
      "Total reward: 1057.0\n",
      "Mean Reward of that batch 96.0909090909091\n",
      "Average Reward of all training: 82.1423223996337\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  207 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1010.0\n",
      "Mean Reward of that batch 112.22222222222223\n",
      "Average Reward of all training: 82.28763592534669\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  208 / 500\n",
      "Number of training episodes: 25\n",
      "Total reward: 1028.0\n",
      "Mean Reward of that batch 41.12\n",
      "Average Reward of all training: 82.08971459878249\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  209 / 500\n",
      "Number of training episodes: 14\n",
      "Total reward: 1033.0\n",
      "Mean Reward of that batch 73.78571428571429\n",
      "Average Reward of all training: 82.0499825398683\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  210 / 500\n",
      "Number of training episodes: 20\n",
      "Total reward: 1009.0\n",
      "Mean Reward of that batch 50.45\n",
      "Average Reward of all training: 81.89950643253559\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  211 / 500\n",
      "Number of training episodes: 11\n",
      "Total reward: 1018.0\n",
      "Mean Reward of that batch 92.54545454545455\n",
      "Average Reward of all training: 81.94996116292857\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  212 / 500\n",
      "Number of training episodes: 15\n",
      "Total reward: 1028.0\n",
      "Mean Reward of that batch 68.53333333333333\n",
      "Average Reward of all training: 81.8866751826003\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  213 / 500\n",
      "Number of training episodes: 14\n",
      "Total reward: 1072.0\n",
      "Mean Reward of that batch 76.57142857142857\n",
      "Average Reward of all training: 81.86172097315817\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  214 / 500\n",
      "Number of training episodes: 14\n",
      "Total reward: 1044.0\n",
      "Mean Reward of that batch 74.57142857142857\n",
      "Average Reward of all training: 81.82765418623421\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  215 / 500\n",
      "Number of training episodes: 16\n",
      "Total reward: 1045.0\n",
      "Mean Reward of that batch 65.3125\n",
      "Average Reward of all training: 81.75083951560056\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  216 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1125.0\n",
      "Mean Reward of that batch 112.5\n",
      "Average Reward of all training: 81.89319674006538\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  217 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1034.0\n",
      "Mean Reward of that batch 147.71428571428572\n",
      "Average Reward of all training: 82.19651973072999\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  218 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1092.0\n",
      "Mean Reward of that batch 136.5\n",
      "Average Reward of all training: 82.44561826407526\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  219 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1167.0\n",
      "Mean Reward of that batch 194.5\n",
      "Average Reward of all training: 82.9572821076183\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  220 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1154.0\n",
      "Mean Reward of that batch 192.33333333333334\n",
      "Average Reward of all training: 83.45444597682611\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  221 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1110.0\n",
      "Mean Reward of that batch 185.0\n",
      "Average Reward of all training: 83.91392812172735\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  222 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1018.0\n",
      "Mean Reward of that batch 169.66666666666666\n",
      "Average Reward of all training: 84.3002017187766\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  223 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1177.0\n",
      "Mean Reward of that batch 196.16666666666666\n",
      "Average Reward of all training: 84.80184505935011\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  224 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1078.0\n",
      "Mean Reward of that batch 154.0\n",
      "Average Reward of all training: 85.11076539390658\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  225 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1121.0\n",
      "Mean Reward of that batch 186.83333333333334\n",
      "Average Reward of all training: 85.56286569585959\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  226 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1072.0\n",
      "Mean Reward of that batch 134.0\n",
      "Average Reward of all training: 85.77718929897526\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  227 / 500\n",
      "Number of training episodes: 11\n",
      "Total reward: 1040.0\n",
      "Mean Reward of that batch 94.54545454545455\n",
      "Average Reward of all training: 85.81581601812275\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  228 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1050.0\n",
      "Mean Reward of that batch 150.0\n",
      "Average Reward of all training: 86.09732559699063\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  229 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1054.0\n",
      "Mean Reward of that batch 175.66666666666666\n",
      "Average Reward of all training: 86.48845809074469\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  230 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1192.0\n",
      "Mean Reward of that batch 198.66666666666666\n",
      "Average Reward of all training: 86.97618943237913\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  231 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1118.0\n",
      "Mean Reward of that batch 186.33333333333334\n",
      "Average Reward of all training: 87.40630693844386\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  232 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 87.89162458095055\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  233 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1054.0\n",
      "Mean Reward of that batch 175.66666666666666\n",
      "Average Reward of all training: 88.26834149977337\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  234 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1069.0\n",
      "Mean Reward of that batch 152.71428571428572\n",
      "Average Reward of all training: 88.54375151778412\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  235 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1193.0\n",
      "Mean Reward of that batch 198.83333333333334\n",
      "Average Reward of all training: 89.01306888721197\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  236 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 89.48335249362209\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  237 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 89.94966746200343\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  238 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 90.4120638172051\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  239 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 90.87059074684022\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  240 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 91.32529661872839\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  241 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 91.77622899790379\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  242 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 92.22343466320172\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  243 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 92.66695962343545\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  244 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 93.10684913317547\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  245 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1108.0\n",
      "Mean Reward of that batch 184.66666666666666\n",
      "Average Reward of all training: 93.48056267412849\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  246 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1029.0\n",
      "Mean Reward of that batch 147.0\n",
      "Average Reward of all training: 93.69812136244505\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  247 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1056.0\n",
      "Mean Reward of that batch 176.0\n",
      "Average Reward of all training: 94.03132734883191\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  248 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1009.0\n",
      "Mean Reward of that batch 144.14285714285714\n",
      "Average Reward of all training: 94.2333899689691\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  249 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1140.0\n",
      "Mean Reward of that batch 190.0\n",
      "Average Reward of all training: 94.61799482853148\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  250 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1096.0\n",
      "Mean Reward of that batch 182.66666666666666\n",
      "Average Reward of all training: 94.97018951588402\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  251 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1131.0\n",
      "Mean Reward of that batch 188.5\n",
      "Average Reward of all training: 95.34281824291237\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  252 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 95.75812451972621\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  253 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 96.1701477429684\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  254 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 96.57892668886223\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  255 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1182.0\n",
      "Mean Reward of that batch 197.0\n",
      "Average Reward of all training: 96.97273481949414\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  256 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1178.0\n",
      "Mean Reward of that batch 168.28571428571428\n",
      "Average Reward of all training: 97.25130114553406\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  257 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 97.65110153018179\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  258 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 98.04780268704154\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  259 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1177.0\n",
      "Mean Reward of that batch 196.16666666666666\n",
      "Average Reward of all training: 98.42663999970418\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  260 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1046.0\n",
      "Mean Reward of that batch 149.42857142857142\n",
      "Average Reward of all training: 98.6228012744306\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  261 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 99.01121966035232\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  262 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 99.39667302042731\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  263 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 99.77919517624318\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  264 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 100.15881943693923\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  265 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 100.5355786088753\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  266 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 100.90950500508254\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  267 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 101.2806304545017\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  268 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 101.64898631101475\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  269 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 102.01460346227493\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  270 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 102.37751233834058\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  271 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 102.73774292011791\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  272 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 103.09532474761748\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  273 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 103.45028692802914\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  274 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 103.80265814362028\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  275 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1193.0\n",
      "Mean Reward of that batch 198.83333333333334\n",
      "Average Reward of all training: 104.14822423521925\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  276 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1093.0\n",
      "Mean Reward of that batch 156.14285714285714\n",
      "Average Reward of all training: 104.33661058633386\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  277 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1119.0\n",
      "Mean Reward of that batch 139.875\n",
      "Average Reward of all training: 104.46490802104024\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  278 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1018.0\n",
      "Mean Reward of that batch 145.42857142857142\n",
      "Average Reward of all training: 104.61225932826157\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  279 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1139.0\n",
      "Mean Reward of that batch 142.375\n",
      "Average Reward of all training: 104.74760965324988\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  280 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1120.0\n",
      "Mean Reward of that batch 160.0\n",
      "Average Reward of all training: 104.944939618774\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  281 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1071.0\n",
      "Mean Reward of that batch 119.0\n",
      "Average Reward of all training: 104.99495762724811\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  282 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1081.0\n",
      "Mean Reward of that batch 120.11111111111111\n",
      "Average Reward of all training: 105.04856100839655\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  283 / 500\n",
      "Number of training episodes: 12\n",
      "Total reward: 1028.0\n",
      "Mean Reward of that batch 85.66666666666667\n",
      "Average Reward of all training: 104.98007374923849\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  284 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1098.0\n",
      "Mean Reward of that batch 137.25\n",
      "Average Reward of all training: 105.09370025012146\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  285 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1026.0\n",
      "Mean Reward of that batch 171.0\n",
      "Average Reward of all training: 105.32495042468243\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  286 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1006.0\n",
      "Mean Reward of that batch 167.66666666666666\n",
      "Average Reward of all training: 105.54292845350055\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  287 / 500\n",
      "Number of training episodes: 12\n",
      "Total reward: 1072.0\n",
      "Mean Reward of that batch 89.33333333333333\n",
      "Average Reward of all training: 105.48644902799475\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  288 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1016.0\n",
      "Mean Reward of that batch 169.33333333333334\n",
      "Average Reward of all training: 105.7081395984994\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  289 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1024.0\n",
      "Mean Reward of that batch 128.0\n",
      "Average Reward of all training: 105.7852740635565\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  290 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1094.0\n",
      "Mean Reward of that batch 136.75\n",
      "Average Reward of all training: 105.89204898057872\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  291 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1121.0\n",
      "Mean Reward of that batch 112.1\n",
      "Average Reward of all training: 105.9133821455939\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  292 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1011.0\n",
      "Mean Reward of that batch 168.5\n",
      "Average Reward of all training: 106.12771987797201\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  293 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1083.0\n",
      "Mean Reward of that batch 154.71428571428572\n",
      "Average Reward of all training: 106.29354433475125\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  294 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1038.0\n",
      "Mean Reward of that batch 173.0\n",
      "Average Reward of all training: 106.52043704109563\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  295 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1120.0\n",
      "Mean Reward of that batch 186.66666666666666\n",
      "Average Reward of all training: 106.7921191754196\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  296 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1136.0\n",
      "Mean Reward of that batch 189.33333333333334\n",
      "Average Reward of all training: 107.0709746286558\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  297 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 107.38386696997345\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  298 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 107.69465936269167\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  299 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 108.00337287652881\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  300 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1194.0\n",
      "Mean Reward of that batch 199.0\n",
      "Average Reward of all training: 108.30669496694038\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  301 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 108.611323887316\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  302 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 108.91393539762291\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  303 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 109.21454947221821\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  304 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 109.51318582263855\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  305 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1140.0\n",
      "Mean Reward of that batch 190.0\n",
      "Average Reward of all training: 109.77707701666267\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  306 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1119.0\n",
      "Mean Reward of that batch 159.85714285714286\n",
      "Average Reward of all training: 109.94073736254659\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  307 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1014.0\n",
      "Mean Reward of that batch 144.85714285714286\n",
      "Average Reward of all training: 110.05447158239869\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  308 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1090.0\n",
      "Mean Reward of that batch 155.71428571428572\n",
      "Average Reward of all training: 110.20271773217756\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  309 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1121.0\n",
      "Mean Reward of that batch 160.14285714285714\n",
      "Average Reward of all training: 110.36433630632214\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  310 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1059.0\n",
      "Mean Reward of that batch 151.28571428571428\n",
      "Average Reward of all training: 110.49634075141695\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  311 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1057.0\n",
      "Mean Reward of that batch 105.7\n",
      "Average Reward of all training: 110.48091843388829\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  312 / 500\n",
      "Number of training episodes: 14\n",
      "Total reward: 1057.0\n",
      "Mean Reward of that batch 75.5\n",
      "Average Reward of all training: 110.36880010557455\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  313 / 500\n",
      "Number of training episodes: 14\n",
      "Total reward: 1012.0\n",
      "Mean Reward of that batch 72.28571428571429\n",
      "Average Reward of all training: 110.2471289048721\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  314 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1045.0\n",
      "Mean Reward of that batch 104.5\n",
      "Average Reward of all training: 110.22882594657634\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  315 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1017.0\n",
      "Mean Reward of that batch 101.7\n",
      "Average Reward of all training: 110.2017503086507\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  316 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1091.0\n",
      "Mean Reward of that batch 121.22222222222223\n",
      "Average Reward of all training: 110.23662521976959\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  317 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1063.0\n",
      "Mean Reward of that batch 118.11111111111111\n",
      "Average Reward of all training: 110.26146586926909\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  318 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1087.0\n",
      "Mean Reward of that batch 108.7\n",
      "Average Reward of all training: 110.25655559923996\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  319 / 500\n",
      "Number of training episodes: 16\n",
      "Total reward: 1074.0\n",
      "Mean Reward of that batch 67.125\n",
      "Average Reward of all training: 110.12134696099783\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  320 / 500\n",
      "Number of training episodes: 15\n",
      "Total reward: 1029.0\n",
      "Mean Reward of that batch 68.6\n",
      "Average Reward of all training: 109.9915927517447\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  321 / 500\n",
      "Number of training episodes: 10\n",
      "Total reward: 1032.0\n",
      "Mean Reward of that batch 103.2\n",
      "Average Reward of all training: 109.9704351419262\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  322 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1091.0\n",
      "Mean Reward of that batch 121.22222222222223\n",
      "Average Reward of all training: 110.00537858006375\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  323 / 500\n",
      "Number of training episodes: 8\n",
      "Total reward: 1044.0\n",
      "Mean Reward of that batch 130.5\n",
      "Average Reward of all training: 110.06882942037315\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  324 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1126.0\n",
      "Mean Reward of that batch 160.85714285714286\n",
      "Average Reward of all training: 110.22558347419034\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  325 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1167.0\n",
      "Mean Reward of that batch 194.5\n",
      "Average Reward of all training: 110.48488937119284\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  326 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1145.0\n",
      "Mean Reward of that batch 190.83333333333334\n",
      "Average Reward of all training: 110.73135699070862\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  327 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1105.0\n",
      "Mean Reward of that batch 184.16666666666666\n",
      "Average Reward of all training: 110.9559298031733\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  328 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 111.22740562694412\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  329 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 111.49723114175585\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  330 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 111.76542135041718\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  331 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 112.03199107443406\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  332 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 112.29695495673998\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  333 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 112.5603274643774\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  334 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 112.82212289113076\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  335 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 113.08235536011246\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  336 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1084.0\n",
      "Mean Reward of that batch 180.66666666666666\n",
      "Average Reward of all training: 113.28349914376291\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  337 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1128.0\n",
      "Mean Reward of that batch 188.0\n",
      "Average Reward of all training: 113.50520982879625\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  338 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1124.0\n",
      "Mean Reward of that batch 160.57142857142858\n",
      "Average Reward of all training: 113.64445899667386\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  339 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1101.0\n",
      "Mean Reward of that batch 157.28571428571428\n",
      "Average Reward of all training: 113.77319426301322\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  340 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1177.0\n",
      "Mean Reward of that batch 168.14285714285714\n",
      "Average Reward of all training: 113.93310503618923\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  341 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 114.18550062259337\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  342 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 114.43642021141619\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  343 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 114.68587671225754\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  344 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 114.93388288460564\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  345 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 115.18045134001257\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  346 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 115.42559454423218\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  347 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 115.66932481932086\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  348 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 115.91165434570212\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  349 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 116.1525951641958\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  350 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 116.39215917801239\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  351 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 116.6303581547132\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  352 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 116.86720372813733\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  353 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 117.10270740029557\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  354 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 117.3368805432326\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  355 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 117.56973440085729\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  356 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 117.80128009074252\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  357 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 118.03152860589451\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  358 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 118.26049081649256\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  359 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 118.48817747159983\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  360 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 118.71459920084538\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  361 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 118.93976651607849\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  362 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 119.1636898129954\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  363 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 119.38637937273921\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  364 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 119.60784536347346\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  365 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 119.82809784192969\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  366 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 120.04714675492988\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  367 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 120.26500194088375\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  368 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 120.48167313126179\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  369 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 120.69716995204428\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  370 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 120.91150192514685\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  371 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 121.12467846982301\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  372 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 121.33670890404392\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  373 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 121.54760244585613\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  374 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 121.75736821471747\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  375 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 121.96601523281157\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  376 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 122.17355242634132\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  377 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 122.37998862680197\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  378 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 122.58533257223371\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  379 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 122.78959290845474\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  380 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 122.99277819027459\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  381 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 123.19489688268857\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  382 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 123.39595736205325\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  383 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 123.59596791724371\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  384 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 123.79493675079254\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  385 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 123.99287198001126\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  386 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 124.18978163809413\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  387 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 124.385673675205\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  388 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 124.58055595954725\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  389 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 124.77443627841731\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  390 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 124.96732233924189\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  391 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 125.15922177059933\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  392 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 125.35014212322535\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  393 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1034.0\n",
      "Mean Reward of that batch 172.33333333333334\n",
      "Average Reward of all training: 125.46969222808566\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  394 / 500\n",
      "Number of training episodes: 42\n",
      "Total reward: 1019.0\n",
      "Mean Reward of that batch 24.261904761904763\n",
      "Average Reward of all training: 125.2128196710649\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  395 / 500\n",
      "Number of training episodes: 33\n",
      "Total reward: 1027.0\n",
      "Mean Reward of that batch 31.12121212121212\n",
      "Average Reward of all training: 124.97461306967288\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  396 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1199.0\n",
      "Mean Reward of that batch 133.22222222222223\n",
      "Average Reward of all training: 124.99544036551265\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  397 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 125.18436872731236\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  398 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 125.37234770035931\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  399 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 125.5593844229148\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  400 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1153.0\n",
      "Mean Reward of that batch 192.16666666666666\n",
      "Average Reward of all training: 125.72590262852418\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  401 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 125.91112481648297\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  402 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 126.09542550101908\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  403 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1137.0\n",
      "Mean Reward of that batch 189.5\n",
      "Average Reward of all training: 126.25275695138876\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  404 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 126.43529963220216\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  405 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 126.61694086767821\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  406 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 126.79768731874303\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  407 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 126.97754558085914\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  408 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 127.15652218482765\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  409 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 127.33462359757868\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  410 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 127.51185622295044\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  411 / 500\n",
      "Number of training episodes: 7\n",
      "Total reward: 1187.0\n",
      "Mean Reward of that batch 169.57142857142858\n",
      "Average Reward of all training: 127.61419094885912\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  412 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1023.0\n",
      "Mean Reward of that batch 170.5\n",
      "Average Reward of all training: 127.71828271840073\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  413 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 127.89329898300508\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  414 / 500\n",
      "Number of training episodes: 9\n",
      "Total reward: 1064.0\n",
      "Mean Reward of that batch 118.22222222222223\n",
      "Average Reward of all training: 127.86993889421093\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  415 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 128.04374627036947\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  416 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 128.2167180341426\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  417 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 128.38886019713027\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  418 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 128.56017871340507\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  419 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 128.73067948019886\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  420 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 128.90036833857934\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  421 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 129.06925107411715\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  422 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 129.2373334175434\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  423 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 129.40462104539793\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  424 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 129.5711195806682\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  425 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 129.7368345934196\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  426 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 129.90177160141624\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  427 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 130.06593607073376\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  428 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 130.2293334163629\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  429 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 130.39196900280493\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  430 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 130.55384814465887\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  431 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 130.71497610720027\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  432 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 130.87535810695215\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  433 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 131.0349993122479\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  434 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 131.19390484378647\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  435 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 131.35207977518007\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  436 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 131.50952913349388\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  437 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 131.6662578997788\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  438 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 131.82227100959665\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  439 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 131.97757335353833\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  440 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 132.13216977773482\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  441 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 132.28606508436127\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  442 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1187.0\n",
      "Mean Reward of that batch 197.83333333333334\n",
      "Average Reward of all training: 132.43436207134988\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  443 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 132.58688044139197\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  444 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 132.7387117917492\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  445 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 132.88986075401493\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  446 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 133.0403319182436\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  447 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 133.1901298334153\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  448 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 133.33925900789433\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  449 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 133.4877239098812\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  450 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 133.63552896785924\n",
      "Max reward for a batch so far: 0\n",
      "===============================\n",
      "Epoch:  451 / 500\n",
      "Number of training episodes: 6\n",
      "Total reward: 1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 133.78267857103472\n",
      "Max reward for a batch so far: 0\n"
     ]
    }
   ],
   "source": [
    "#===================\n",
    "# Training and Printing some stats\n",
    "#===================\n",
    "allRewards =[]\n",
    "total_rewards =0\n",
    "maximumRewardRecorded =0\n",
    "mean_reward_total =[]\n",
    "num_epochs =2\n",
    "average_reward=[]\n",
    "training = True\n",
    "epoch = 1\n",
    "\n",
    "# saver\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if training:\n",
    "    while epoch < num_epochs +1:\n",
    "        states_mb, actions_mb, rewards_of_batch, discounted_rewards_mb, nb_episodes_mb = make_batch(1000)\n",
    "        # total rewards of the batch\n",
    "        total_reward_of_that_batch = np.sum(rewards_of_batch)\n",
    "        allRewards.append(total_reward_of_that_batch)\n",
    "\n",
    "        # calculate the mean reward of the batch\n",
    "        mean_reward_of_that_batch = np.divide(total_reward_of_that_batch, nb_episodes_mb)\n",
    "        mean_reward_total.append(mean_reward_of_that_batch)\n",
    "\n",
    "        # calculate the average reward of all training\n",
    "        average_reward_of_all_training = np.divide(np.sum(mean_reward_total), epoch)\n",
    "\n",
    "        # maximum reward recorded\n",
    "        max_reward_recorded = np.amax(allRewards)\n",
    "\n",
    "        print(\"===============================\")\n",
    "        print(\"Epoch: \", epoch, \"/\", num_epochs)\n",
    "        print(\"Number of training episodes: {}\".format(nb_episodes_mb))\n",
    "        print(\"Total reward: {}\".format(total_reward_of_that_batch, nb_episodes_mb))\n",
    "        print(\"Mean Reward of that batch {}\".format(mean_reward_of_that_batch))\n",
    "        print(\"Average Reward of all training: {}\".format(average_reward_of_all_training))\n",
    "        print(\"Max reward for a batch so far: {}\".format(maximumRewardRecorded))\n",
    "        \n",
    "        # Jieda add: update the ValueNetwork parameter, and make an estimate of Value function for each given St\n",
    "        feed_dict_value = {self.state:states_mb, self.target:discounted_rewards_mb}\n",
    "        _, loss = sess.run([ValueNetwork.train_opt, ValueNetwork.loss], feed_dict_value)\n",
    "        \n",
    "        # Now make a prediction of value function using the updated ValueNetwork parameters\n",
    "        \n",
    "        value_prediction = ValueNetowrk.predict(states_mb)\n",
    "        print(\"debug, shape of value_prediction\")\n",
    "        print(value_prediction.shape)\n",
    "        \n",
    "        # compute the discounted total rewards minus baseline\n",
    "        # shape of discounted_rewards_mb should be an array of length (number of 4 tuples in that batch)\n",
    "        # shape of value_prediction should also be an array of length (number of 4 tuples in that batch)\n",
    "        # Note: 4 tuples are essentially samples (st,at,rt,st+1)\n",
    "        discounted_rewards_mb_minus_baseline = discounted_rewards_mb - value_prediction\n",
    "        print(\"debug: shape of discounted_rewards_mb and discounted_rewards_mb_minus_baseline\")\n",
    "        print(discounted_rewards_mb.shape)\n",
    "        print(discounted_rewards_mb_minus_baseline.shape)\n",
    "        \n",
    "        # Now update the Policy Network with a baseline that is the ValueNetwork Prediction\n",
    "        loss_,_ = sess.run([PolicyNetwork.loss,PolicyNetwork.train_opt], \\\n",
    "                feed_dict={PolicyNetwork.inputs: states_mb, PolicyNetwork.actions: actions_mb, PolicyNetwork.discounted_episode_rewards: discounted_rewards_mb_minus_baseline})\n",
    "\n",
    "        # update epoch\n",
    "        epoch +=1\n",
    "\n",
    "# plot the average episode reward vs epoch\n",
    "# episode reward is the total undiscounted reward for an episode\n",
    "plt.plot(range(0,len(mean_reward_total)), mean_reward_total)\n",
    "plt.savefig('./average_reward_vs_epoch_baseline.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the average reward over epochs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
